import { Edge } from '@xyflow/react';

export type AbstractionLevel = 'field' | 'theory' | 'method' | 'algorithm' | 'implementation';
export type Language = 'ru' | 'en';

export interface NodeContent {
  label: string;
  description: string;
  keyPoints: string[];
  howItWorks: string; // –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º–∞
}

export interface AINodeData {
  emoji?: string;
  level: AbstractionLevel;
  ru: NodeContent;
  en: NodeContent;
  [key: string]: unknown;
}

export interface AINode {
  id: string;
  position: { x: number; y: number };
  type: string;
  data: AINodeData;
}

// –¶–≤–µ—Ç–∞ –ø–æ —É—Ä–æ–≤–Ω—é –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏
export const levelColors: Record<AbstractionLevel, string> = {
  field: '#6366f1',
  theory: '#8b5cf6',
  method: '#06b6d4',
  algorithm: '#10b981',
  implementation: '#f59e0b',
};

export const levelLabels: Record<Language, Record<AbstractionLevel, string>> = {
  ru: {
    field: '–û–±–ª–∞—Å—Ç—å',
    theory: '–¢–µ–æ—Ä–∏—è',
    method: '–ú–µ—Ç–æ–¥',
    algorithm: '–ê–ª–≥–æ—Ä–∏—Ç–º',
    implementation: '–ò–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—è',
  },
  en: {
    field: 'Field',
    theory: 'Theory',
    method: 'Method',
    algorithm: 'Algorithm',
    implementation: 'Implementation',
  },
};

// ==================== NODES ====================

export const initialNodes: AINode[] = [
  // ========== FIELD ==========
  {
    id: 'ai',
    position: { x: 600, y: 0 },
    type: 'custom',
    data: {
      emoji: 'ü§ñ',
      level: 'field',
      ru: {
        label: '–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç',
        description: '–û–±–ª–∞—Å—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã—Ö –Ω–∞—É–∫, —Å–æ–∑–¥–∞—é—â–∞—è —Å–∏—Å—Ç–µ–º—ã, —Å–ø–æ—Å–æ–±–Ω—ã–µ –≤—ã–ø–æ–ª–Ω—è—Ç—å –∑–∞–¥–∞—á–∏, —Ç—Ä–µ–±—É—é—â–∏–µ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.',
        keyPoints: [
          'üìÖ –¢–µ—Ä–º–∏–Ω –≤–≤–µ–¥—ë–Ω –≤ 1956 –≥–æ–¥—É (–î–∂–æ–Ω –ú–∞–∫–∫–∞—Ä—Ç–∏)',
          'üéØ –¶–µ–ª—å: –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á',
          'üîÄ –í–∫–ª—é—á–∞–µ—Ç: ML, —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫—É, NLP, CV',
          '‚ö° –°–µ–π—á–∞—Å: —ç—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ AI (2022+)',
        ],
        howItWorks: 'AI —Å–∏—Å—Ç–µ–º—ã —Ä–∞–±–æ—Ç–∞—é—Ç –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø—É: –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ‚Üí –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–∞–ª–≥–æ—Ä–∏—Ç–º—ã/–º–æ–¥–µ–ª–∏) ‚Üí –≤—ã—Ö–æ–¥–Ω–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π AI –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏: –≤–º–µ—Å—Ç–æ —è–≤–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∞–≤–∏–ª, —Å–∏—Å—Ç–µ–º–∞ —É—á–∏—Ç—Å—è –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö. –ü—Ä–æ—Ü–µ—Å—Å: 1) –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö 2) –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö 3) –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ 4) –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ –Ω–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º. AI –º–æ–∂–µ—Ç –±—ã—Ç—å —É–∑–∫–∏–º (–æ–¥–Ω–∞ –∑–∞–¥–∞—á–∞) –∏–ª–∏ –æ–±—â–∏–º (AGI ‚Äî –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á, –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç).',
      },
      en: {
        label: 'Artificial Intelligence',
        description: 'Field of computer science creating systems capable of performing tasks that require human intelligence.',
        keyPoints: [
          'üìÖ Term coined in 1956 (John McCarthy)',
          'üéØ Goal: automate cognitive tasks',
          'üîÄ Includes: ML, robotics, NLP, CV',
          '‚ö° Now: generative AI era (2022+)',
        ],
        howItWorks: 'AI systems work on principle: input data ‚Üí processing (algorithms/models) ‚Üí output result. Modern AI is based on machine learning: instead of explicit rule programming, system learns from examples. Process: 1) Collect data 2) Train model on data 3) Validate quality 4) Apply to new data. AI can be narrow (single task) or general (AGI ‚Äî multiple tasks, not yet achieved).',
      },
    },
  },

  // ========== THEORY ==========
  {
    id: 'ml',
    position: { x: 150, y: 120 },
    type: 'custom',
    data: {
      emoji: 'üß†',
      level: 'theory',
      ru: {
        label: '–ú–∞—à–∏–Ω–Ω–æ–µ –û–±—É—á–µ–Ω–∏–µ',
        description: '–ü–∞—Ä–∞–¥–∏–≥–º–∞, –≥–¥–µ —Å–∏—Å—Ç–µ–º—ã —É—á–∞—Ç—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ —è–≤–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∞–≤–∏–ª–∞.',
        keyPoints: [
          'üìä –î–∞–Ω–Ω—ã–µ ‚Üí –ü–∞—Ç—Ç–µ—Ä–Ω—ã ‚Üí –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è',
          'üîÑ –û–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é',
          'üìà –ö–∞—á–µ—Å—Ç–≤–æ —Ä–∞—Å—Ç—ë—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö',
          'üéì –¢—Ä–∏ —Ç–∏–ø–∞: supervised, unsupervised, RL',
        ],
        howItWorks: 'ML –º–æ–¥–µ–ª—å ‚Äî —ç—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–≤–µ—Å–∞–º–∏). –û–±—É—á–µ–Ω–∏–µ: 1) –ú–æ–¥–µ–ª—å –¥–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ 2) –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º —á–µ—Ä–µ–∑ loss function 3) –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏—è) 4) –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ (gradient descent) 5) –ü–æ–≤—Ç–æ—Ä —Ç—ã—Å—è—á–∏ —Ä–∞–∑. –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª—å –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫ –Ω–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º (inference). –ö–ª—é—á–µ–≤–æ–µ: –º–æ–¥–µ–ª—å –Ω–∞—Ö–æ–¥–∏—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å–∞–º–∞, –∞ –Ω–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç –∏—Ö –∑–∞–¥–∞—ë—Ç.',
      },
      en: {
        label: 'Machine Learning',
        description: 'Paradigm where systems learn from data without explicit programming of every rule.',
        keyPoints: [
          'üìä Data ‚Üí Patterns ‚Üí Predictions',
          'üîÑ Learning through iterative optimization',
          'üìà Quality improves with more data',
          'üéì Three types: supervised, unsupervised, RL',
        ],
        howItWorks: 'ML model is a mathematical function with adjustable parameters (weights). Training: 1) Model makes prediction 2) Compare with correct answer via loss function 3) Compute gradient (improvement direction) 4) Update weights (gradient descent) 5) Repeat thousands of times. After training, model is applied to new data (inference). Key: model finds patterns itself, programmer doesn\'t specify them.',
      },
    },
  },
  {
    id: 'dl',
    position: { x: 600, y: 120 },
    type: 'custom',
    data: {
      emoji: 'üß¨',
      level: 'theory',
      ru: {
        label: '–ì–ª—É–±–æ–∫–æ–µ –û–±—É—á–µ–Ω–∏–µ',
        description: '–ü–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ ML —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏ –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Å–ª–æ—ë–≤, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞—é—â–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏.',
        keyPoints: [
          'üèóÔ∏è –ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ (3+ —Å–ª–æ—ë–≤)',
          'üîç –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤',
          'üí™ –¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö –∏ GPU',
          'üöÄ –ü—Ä–æ—Ä—ã–≤: ImageNet 2012 (AlexNet)',
        ],
        howItWorks: 'Deep Learning –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º —Å–ª–æ—ë–≤. –ö–∞–∂–¥—ã–π —Å–ª–æ–π –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å—ë –±–æ–ª–µ–µ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: –ø–µ—Ä–≤—ã–µ —Å–ª–æ–∏ ‚Äî –ø—Ä–æ—Å—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (–ª–∏–Ω–∏–∏, –∫—Ä–∞—è), —Å—Ä–µ–¥–Ω–∏–µ ‚Äî —Ñ–æ—Ä–º—ã, –≥–ª—É–±–æ–∫–∏–µ ‚Äî –æ–±—ä–µ–∫—Ç—ã —Ü–µ–ª–∏–∫–æ–º. –û–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ backpropagation: –æ—à–∏–±–∫–∞ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞–∑–∞–¥ –ø–æ —Å–µ—Ç–∏, –∫–∞–∂–¥—ã–π –Ω–µ–π—Ä–æ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç —Å–≤–æ–∏ –≤–µ—Å–∞. "–ì–ª—É–±–∏–Ω–∞" –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏. –¢—Ä–µ–±—É–µ—Ç GPU –∏–∑-–∑–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –º–∞—Ç—Ä–∏—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π.',
      },
      en: {
        label: 'Deep Learning',
        description: 'Subset of ML with multi-layer neural networks that automatically extract features.',
        keyPoints: [
          'üèóÔ∏è Multi-layer neural networks (3+ layers)',
          'üîç Automatic feature extraction',
          'üí™ Requires lots of data and GPUs',
          'üöÄ Breakthrough: ImageNet 2012 (AlexNet)',
        ],
        howItWorks: 'Deep Learning uses neural networks with many layers. Each layer extracts increasingly abstract features: first layers ‚Äî simple patterns (lines, edges), middle ‚Äî shapes, deep ‚Äî whole objects. Training via backpropagation: error propagates backward through network, each neuron adjusts its weights. "Depth" allows modeling complex nonlinear dependencies. Requires GPU due to parallel matrix operations.',
      },
    },
  },
  {
    id: 'nlp',
    position: { x: 1050, y: 120 },
    type: 'custom',
    data: {
      emoji: 'üí¨',
      level: 'theory',
      ru: {
        label: '–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ø–∑—ã–∫–∞',
        description: '–¢–µ–æ—Ä–∏—è –∏ –º–µ—Ç–æ–¥—ã –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.',
        keyPoints: [
          'üìù –¢–µ–∫—Å—Ç –∫–∞–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–æ–≤',
          'üåê –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ',
          'üî§ –≠—Ç–∞–ø—ã: —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è ‚Üí —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ ‚Üí –º–æ–¥–µ–ª—å',
          'üó£Ô∏è –ó–∞–¥–∞—á–∏: –ø–µ—Ä–µ–≤–æ–¥, —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è, QA',
        ],
        howItWorks: 'NLP –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–æ–¥–µ–ª—å—é. –ü–∞–π–ø–ª–∞–π–Ω: 1) –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è ‚Äî —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –µ–¥–∏–Ω–∏—Ü—ã (—Å–ª–æ–≤–∞/–ø–æ–¥—Å–ª–æ–≤–∞) 2) –≠–º–±–µ–¥–¥–∏–Ω–≥ ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä—ã —á–∏—Å–µ–ª 3) –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–¥–µ–ª—å—é (—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä) ‚Äî –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ 4) –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã—Ö–æ–¥–∞. –ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è: —Å–ª–æ–≤–∞ —Å –ø–æ—Ö–æ–∂–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –∏–º–µ—é—Ç –±–ª–∏–∑–∫–∏–µ –≤–µ–∫—Ç–æ—Ä—ã. –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ LLM –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—Ç —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω, –≥–µ–Ω–µ—Ä–∏—Ä—É—è —Ç–µ–∫—Å—Ç –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ.',
      },
      en: {
        label: 'Natural Language Processing',
        description: 'Theory and methods for understanding, interpreting, and generating human language.',
        keyPoints: [
          'üìù Text as sequence of tokens',
          'üåê Context determines meaning',
          'üî§ Pipeline: tokenization ‚Üí embeddings ‚Üí model',
          'üó£Ô∏è Tasks: translation, summarization, QA',
        ],
        howItWorks: 'NLP converts text to numbers for model processing. Pipeline: 1) Tokenization ‚Äî split into units (words/subwords) 2) Embedding ‚Äî convert tokens to number vectors 3) Model processing (transformer) ‚Äî understand context 4) Decoding ‚Äî generate output. Key idea: words with similar meaning have close vectors. Modern LLMs predict next token, generating text autoregressively.',
      },
    },
  },

  // ========== METHOD (ML) ==========
  {
    id: 'supervised',
    position: { x: -50, y: 260 },
    type: 'custom',
    data: {
      emoji: 'üìä',
      level: 'method',
      ru: {
        label: '–û–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º',
        description: '–ú–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—é –≤—Ö–æ–¥‚Üí–≤—ã—Ö–æ–¥.',
        keyPoints: [
          'üè∑Ô∏è –¢—Ä–µ–±—É–µ—Ç —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (labels)',
          'üéØ –¶–µ–ª—å: –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ—à–∏–±–∫—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è',
          'üìâ Loss function –∏–∑–º–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ',
          'üîÆ –¢–∏–ø—ã: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Ä–µ–≥—Ä–µ—Å—Å–∏—è',
        ],
        howItWorks: '–ü—Ä–æ—Ü–µ—Å—Å: 1) –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –ø–∞—Ä–∞–º–∏ (–≤—Ö–æ–¥, –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π_–æ—Ç–≤–µ—Ç) 2) –ú–æ–¥–µ–ª—å –¥–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –≤—Ö–æ–¥–∞ 3) Loss function –≤—ã—á–∏—Å–ª—è–µ—Ç –æ—à–∏–±–∫—É –º–µ–∂–¥—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º 4) –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –æ–±–Ω–æ–≤–ª—è–µ—Ç –≤–µ—Å–∞ —á—Ç–æ–±—ã —É–º–µ–Ω—å—à–∏—Ç—å –æ—à–∏–±–∫—É 5) –ü–æ–≤—Ç–æ—Ä –Ω–∞ –≤—Å–µ—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö –º–Ω–æ–≥–æ —ç–ø–æ—Ö. –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: –≤—ã—Ö–æ–¥ ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤, loss ‚Äî cross-entropy. –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏: –≤—ã—Ö–æ–¥ ‚Äî —á–∏—Å–ª–æ, loss ‚Äî MSE.',
      },
      en: {
        label: 'Supervised Learning',
        description: 'Learning method using labeled data: model learns input‚Üíoutput mapping.',
        keyPoints: [
          'üè∑Ô∏è Requires labeled data',
          'üéØ Goal: minimize prediction error',
          'üìâ Loss function measures quality',
          'üîÆ Types: classification, regression',
        ],
        howItWorks: 'Process: 1) Prepare dataset with (input, correct_answer) pairs 2) Model makes prediction for input 3) Loss function computes error between prediction and correct answer 4) Optimizer updates weights to reduce error 5) Repeat on all examples for many epochs. For classification: output ‚Äî class probabilities, loss ‚Äî cross-entropy. For regression: output ‚Äî number, loss ‚Äî MSE.',
      },
    },
  },
  {
    id: 'unsupervised',
    position: { x: 150, y: 260 },
    type: 'custom',
    data: {
      emoji: 'üîç',
      level: 'method',
      ru: {
        label: '–û–±—É—á–µ–Ω–∏–µ –±–µ–∑ —É—á–∏—Ç–µ–ª—è',
        description: '–ú–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —Å–∫—Ä—ã—Ç—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.',
        keyPoints: [
          '‚ùå –ù–µ —Ç—Ä–µ–±—É–µ—Ç —Ä–∞–∑–º–µ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö',
          'üîé –ù–∞—Ö–æ–¥–∏—Ç —Å–∫—Ä—ã—Ç—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É',
          'üìä –¢–∏–ø—ã: –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è, —Å–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏',
          'üí° –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è, –∞–Ω–æ–º–∞–ª–∏–∏',
        ],
        howItWorks: '–ú–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –±–µ–∑ "–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤". –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –æ–±—ä–µ–∫—Ç—ã –≤–º–µ—Å—Ç–µ (K-Means –Ω–∞—Ö–æ–¥–∏—Ç —Ü–µ–Ω—Ç—Ä—ã –≥—Ä—É–ø–ø). –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏: –Ω–∞—Ö–æ–¥–∏—Ç –≥–ª–∞–≤–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤–∞—Ä–∏–∞—Ü–∏–∏ (PCA –ø—Ä–æ–µ—Ü–∏—Ä—É–µ—Ç –Ω–∞ –º–µ–Ω—å—à–µ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ). –î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π: —É—á–∏—Ç—Å—è –Ω–∞ "–Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö" –¥–∞–Ω–Ω—ã—Ö, –≤—ã–¥–µ–ª—è–µ—Ç –Ω–µ–æ–±—ã—á–Ω—ã–µ. –ö–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ: –Ω–µ—Ç —è–≤–Ω–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π, –º–æ–¥–µ–ª—å —Å–∞–º–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É.',
      },
      en: {
        label: 'Unsupervised Learning',
        description: 'Method for finding hidden patterns in unlabeled data.',
        keyPoints: [
          '‚ùå No labeled data required',
          'üîé Finds hidden structure',
          'üìä Types: clustering, dimensionality reduction',
          'üí° Uses: segmentation, anomaly detection',
        ],
        howItWorks: 'Model analyzes data without "correct answers". Clustering: groups similar objects together (K-Means finds group centers). Dimensionality reduction: finds main variation directions (PCA projects to smaller space). Anomaly detection: learns from "normal" data, identifies unusual ones. Key difference: no explicit target variable, model determines structure itself.',
      },
    },
  },
  {
    id: 'rl',
    position: { x: 350, y: 260 },
    type: 'custom',
    data: {
      emoji: 'üéÆ',
      level: 'method',
      ru: {
        label: '–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º',
        description: '–ú–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å–æ —Å—Ä–µ–¥–æ–π –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–≥—Ä–∞–¥/—à—Ç—Ä–∞—Ñ–æ–≤.',
        keyPoints: [
          'üéØ –ê–≥–µ–Ω—Ç ‚Üí –î–µ–π—Å—Ç–≤–∏–µ ‚Üí –°—Ä–µ–¥–∞ ‚Üí –ù–∞–≥—Ä–∞–¥–∞',
          '‚öñÔ∏è –ë–∞–ª–∞–Ω—Å: –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ vs –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ',
          'üèÜ –¶–µ–ª—å: –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è —Å—É–º–º–∞—Ä–Ω–æ–π –Ω–∞–≥—Ä–∞–¥—ã',
          'üé≤ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: –∏–≥—Ä—ã, —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞, —Ç–æ—Ä–≥–æ–≤–ª—è',
        ],
        howItWorks: '–ê–≥–µ–Ω—Ç –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ (state), –≤—ã–±–∏—Ä–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ (action), –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç –≤ –Ω–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ –ø–æ–ª—É—á–∞–µ—Ç –Ω–∞–≥—Ä–∞–¥—É (reward). –¶–µ–ª—å: –≤—ã—É—á–∏—Ç—å policy ‚Äî —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É—é—â—É—é —Å—É–º–º–∞—Ä–Ω—É—é –Ω–∞–≥—Ä–∞–¥—É. –î–∏–ª–µ–º–º–∞ exploration/exploitation: –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ö–æ—Ä–æ—à–∏–µ? –ú–µ—Ç–æ–¥—ã: Q-learning (—Ç–∞–±–ª–∏—Ü–∞ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –¥–µ–π—Å—Ç–≤–∏–π), Policy Gradient (–Ω–∞–ø—Ä—è–º—É—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é), Actor-Critic (–∫–æ–º–±–∏–Ω–∞—Ü–∏—è).',
      },
      en: {
        label: 'Reinforcement Learning',
        description: 'Method where agent learns through interaction with environment and rewards/penalties.',
        keyPoints: [
          'üéØ Agent ‚Üí Action ‚Üí Environment ‚Üí Reward',
          '‚öñÔ∏è Balance: exploration vs exploitation',
          'üèÜ Goal: maximize cumulative reward',
          'üé≤ Uses: games, robotics, trading',
        ],
        howItWorks: 'Agent is in state, chooses action, transitions to new state and receives reward. Goal: learn policy ‚Äî action selection strategy maximizing cumulative reward. Exploration/exploitation dilemma: explore new actions or use known good ones? Methods: Q-learning (action value table), Policy Gradient (directly optimize strategy), Actor-Critic (combination).',
      },
    },
  },

  // ========== ALGORITHM (ML) ==========
  {
    id: 'linear-reg',
    position: { x: -150, y: 400 },
    type: 'custom',
    data: {
      emoji: 'üìà',
      level: 'algorithm',
      ru: {
        label: '–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è',
        description: '–ü—Ä–æ—Å—Ç–µ–π—à–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —á–µ—Ä–µ–∑ –ª–∏–Ω–µ–π–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å.',
        keyPoints: [
          'üìê –§–æ—Ä–º—É–ª–∞: y = wx + b',
          'üéØ –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è MSE (Mean Squared Error)',
          '‚ö° –ë—ã—Å—Ç—Ä—ã–π, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–π',
          'üìä –ë–∞–∑–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏',
        ],
        howItWorks: '–ü—Ä–µ–¥—Å—Ç–∞–≤—å –≥—Ä–∞—Ñ–∏–∫: –ø–æ X ‚Äî –ø–ª–æ—â–∞–¥—å –∫–≤–∞—Ä—Ç–∏—Ä—ã, –ø–æ Y ‚Äî —Ü–µ–Ω–∞. –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –ø—Ä–æ–≤–æ–¥–∏—Ç –ø—Ä—è–º—É—é –ª–∏–Ω–∏—é —á–µ—Ä–µ–∑ —Ç–æ—á–∫–∏ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∞ –±—ã–ª–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–ª–∏–∑–∫–æ –∫–æ –≤—Å–µ–º.\n\n–§–æ—Ä–º—É–ª–∞ –ª–∏–Ω–∏–∏: y = w¬∑x + b\n‚Ä¢ w (weight) ‚Äî –Ω–∞–∫–ª–æ–Ω –ª–∏–Ω–∏–∏. –ë–æ–ª—å—à–µ w = –∫—Ä—É—á–µ –Ω–∞–∫–ª–æ–Ω\n‚Ä¢ b (bias) ‚Äî –≥–¥–µ –ª–∏–Ω–∏—è –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç –æ—Å—å Y\n\n–ö–∞–∫ —É—á–∏—Ç—Å—è: –º–æ–¥–µ–ª—å –ø—Ä–æ–±—É–µ—Ç —Ä–∞–∑–Ω—ã–µ w –∏ b, –∏–∑–º–µ—Ä—è–µ—Ç –æ—à–∏–±–∫—É (MSE ‚Äî —Å—Ä–µ–¥–Ω–∏–π –∫–≤–∞–¥—Ä–∞—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç —Ç–æ—á–µ–∫ –¥–æ –ª–∏–Ω–∏–∏), –∏ —à–∞–≥ –∑–∞ —à–∞–≥–æ–º —É–º–µ–Ω—å—à–∞–µ—Ç –µ—ë. –≠—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è gradient descent ‚Äî –¥–≤–∏–≥–∞–µ–º—Å—è –≤ —Å—Ç–æ—Ä–æ–Ω—É –º–µ–Ω—å—à–µ–π –æ—à–∏–±–∫–∏.\n\n‚ö†Ô∏è –†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏–Ω–µ–π–Ω–∞—è!',
      },
      en: {
        label: 'Linear Regression',
        description: 'Simplest algorithm for predicting continuous values through linear relationship.',
        keyPoints: [
          'üìê Formula: y = wx + b',
          'üéØ Minimizes MSE (Mean Squared Error)',
          '‚ö° Fast, interpretable',
          'üìä Baseline algorithm for regression',
        ],
        howItWorks: 'Imagine a chart: X axis ‚Äî apartment size, Y axis ‚Äî price. Linear regression draws a straight line through points so it\'s as close as possible to all of them.\n\nLine formula: y = w¬∑x + b\n‚Ä¢ w (weight) ‚Äî line slope. Higher w = steeper slope\n‚Ä¢ b (bias) ‚Äî where line crosses Y axis\n\nHow it learns: model tries different w and b, measures error (MSE ‚Äî average squared distance from points to line), and step by step reduces it. This is called gradient descent ‚Äî moving toward smaller error.\n\n‚ö†Ô∏è Only works if relationship is actually linear!',
      },
    },
  },
  {
    id: 'decision-tree',
    position: { x: 30, y: 400 },
    type: 'custom',
    data: {
      emoji: 'üå≥',
      level: 'algorithm',
      ru: {
        label: '–î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π',
        description: '–ê–ª–≥–æ—Ä–∏—Ç–º, —Ä–∞–∑–±–∏–≤–∞—é—â–∏–π –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —É—Å–ª–æ–≤–∏–π (if-else).',
        keyPoints: [
          'üîÄ –ö–∞–∂–¥—ã–π —É–∑–µ–ª = —É—Å–ª–æ–≤–∏–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è',
          'üçÉ –õ–∏—Å—Ç—å—è = –∏—Ç–æ–≥–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ',
          'üëÅÔ∏è –õ–µ–≥–∫–æ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –ø–æ–Ω—è—Ç—å',
          '‚ö†Ô∏è –°–∫–ª–æ–Ω–µ–Ω –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é',
        ],
        howItWorks: '–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ: 1) –í—ã–±—Ä–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫ –∏ –ø–æ—Ä–æ–≥ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è 2) –ö—Ä–∏—Ç–µ—Ä–∏–π: –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è "—á–∏—Å—Ç–æ—Ç—ã" –≥—Ä—É–ø–ø (Gini, Entropy) 3) –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Ä–∞–∑–±–∏–≤–∞—Ç—å –¥–æ —É—Å–ª–æ–≤–∏—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏. –ü—Ä–∏–º–µ—Ä: "–í–æ–∑—Ä–∞—Å—Ç > 30? –î–∞ ‚Üí –î–æ—Ö–æ–¥ > 50k? –î–∞ ‚Üí –û–¥–æ–±—Ä–∏—Ç—å –∫—Ä–µ–¥–∏—Ç". –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: –∏–¥—ë–º –æ—Ç –∫–æ—Ä–Ω—è –ø–æ —É—Å–ª–æ–≤–∏—è–º –¥–æ –ª–∏—Å—Ç–∞. –õ–µ–≥–∫–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å, –Ω–æ –≥–ª—É–±–æ–∫–æ–µ –¥–µ—Ä–µ–≤–æ –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ (overfitting). –†–µ—à–µ–Ω–∏–µ: –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –≥–ª—É–±–∏–Ω—É –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª–∏.',
      },
      en: {
        label: 'Decision Tree',
        description: 'Algorithm splitting data through sequence of conditions (if-else).',
        keyPoints: [
          'üîÄ Each node = split condition',
          'üçÉ Leaves = final prediction',
          'üëÅÔ∏è Easy to visualize and understand',
          '‚ö†Ô∏è Prone to overfitting',
        ],
        howItWorks: 'Building: 1) Choose feature and threshold for split 2) Criterion: maximize group "purity" (Gini, Entropy) 3) Recursively split until stopping condition. Example: "Age > 30? Yes ‚Üí Income > 50k? Yes ‚Üí Approve loan". Prediction: go from root through conditions to leaf. Easy to interpret, but deep tree memorizes training data (overfitting). Solution: limit depth or use ensembles.',
      },
    },
  },
  {
    id: 'random-forest',
    position: { x: 210, y: 400 },
    type: 'custom',
    data: {
      emoji: 'üå≤',
      level: 'algorithm',
      ru: {
        label: 'Random Forest',
        description: '–ê–Ω—Å–∞–º–±–ª—å –¥–µ—Ä–µ–≤—å–µ–≤ —Ä–µ—à–µ–Ω–∏–π, –≥–æ–ª–æ—Å—É—é—â–∏—Ö –∑–∞ –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.',
        keyPoints: [
          'üå≥ –ú–Ω–æ–≥–æ –¥–µ—Ä–µ–≤—å–µ–≤ (100-1000)',
          'üé≤ –ö–∞–∂–¥–æ–µ –Ω–∞ —Å–ª—É—á–∞–π–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ',
          'üó≥Ô∏è –ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ/—É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤',
          'üí™ –£—Å—Ç–æ–π—á–∏–≤ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é',
        ],
        howItWorks: '–ò–¥–µ—è: –º–Ω–æ–≥–æ "—Å–ª–∞–±—ã—Ö" –º–æ–¥–µ–ª–µ–π –≤–º–µ—Å—Ç–µ –¥–∞—é—Ç "—Å–∏–ª—å–Ω—É—é". –û–±—É—á–µ–Ω–∏–µ: 1) –î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞ –≤–∑—è—Ç—å bootstrap-–≤—ã–±–æ—Ä–∫—É (—Å –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è–º–∏) 2) –í –∫–∞–∂–¥–æ–º —É–∑–ª–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å —Å–ª—É—á–∞–π–Ω–æ–µ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ 3) –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –¥–µ—Ä–µ–≤–æ –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ‚Äî –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞, —Ä–µ–≥—Ä–µ—Å—Å–∏—è ‚Äî —Å—Ä–µ–¥–Ω–µ–µ. –†–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏—è —É–º–µ–Ω—å—à–∞–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –º–µ–∂–¥—É –¥–µ—Ä–µ–≤—å—è–º–∏ ‚Üí —Å–Ω–∏–∂–∞–µ—Ç –¥–∏—Å–ø–µ—Ä—Å–∏—é ‚Üí –º–µ–Ω—å—à–µ overfitting. –ù–µ–¥–æ—Å—Ç–∞—Ç–æ–∫: —Ç–µ—Ä—è–µ—Ç—Å—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å.',
      },
      en: {
        label: 'Random Forest',
        description: 'Ensemble of decision trees voting for final result.',
        keyPoints: [
          'üå≥ Many trees (100-1000)',
          'üé≤ Each on random sample',
          'üó≥Ô∏è Voting/averaging results',
          'üí™ Robust to overfitting',
        ],
        howItWorks: 'Idea: many "weak" models together make "strong" one. Training: 1) For each tree take bootstrap sample (with replacement) 2) At each node consider random subset of features 3) Build tree without restrictions. Prediction: classification ‚Äî majority vote, regression ‚Äî average. Randomization reduces correlation between trees ‚Üí reduces variance ‚Üí less overfitting. Downside: loses interpretability.',
      },
    },
  },
  {
    id: 'svm',
    position: { x: -150, y: 520 },
    type: 'custom',
    data: {
      emoji: '‚öîÔ∏è',
      level: 'algorithm',
      ru: {
        label: 'SVM',
        description: 'Support Vector Machine ‚Äî –Ω–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –≥–∏–ø–µ—Ä–ø–ª–æ—Å–∫–æ—Å—Ç—å –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤.',
        keyPoints: [
          'üìè –ú–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç –æ—Ç—Å—Ç—É–ø –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏',
          'üîÆ Kernel trick –¥–ª—è –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü',
          'üí™ –†–∞–±–æ—Ç–∞–µ—Ç –≤ –≤—ã—Å–æ–∫–∏—Ö —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è—Ö',
          'üìä –•–æ—Ä–æ—à –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤',
        ],
        howItWorks: '–¶–µ–ª—å: –Ω–∞–π—Ç–∏ –≥–∏–ø–µ—Ä–ø–ª–æ—Å–∫–æ—Å—Ç—å, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É–¥–∞–ª—ë–Ω–Ω—É—é –æ—Ç –±–ª–∏–∂–∞–π—à–∏—Ö —Ç–æ—á–µ–∫ –æ–±–æ–∏—Ö –∫–ª–∞—Å—Å–æ–≤ (support vectors). Margin = —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –±–ª–∏–∂–∞–π—à–∏—Ö —Ç–æ—á–µ–∫ √ó 2. Kernel trick: –ø—Ä–æ–µ—Ü–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –±–æ–ª—å—à–µ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≥–¥–µ –æ–Ω–∏ –ª–∏–Ω–µ–π–Ω–æ —Ä–∞–∑–¥–µ–ª–∏–º—ã. –ü—Ä–∏–º–µ—Ä—ã —è–¥–µ—Ä: RBF (—Ä–∞–¥–∏–∞–ª—å–Ω–æ–µ), polynomial. Soft margin: –¥–æ–ø—É—Å–∫–∞–µ—Ç –æ—à–∏–±–∫–∏ –ø—Ä–∏ –Ω–µ—Ä–∞–∑–¥–µ–ª–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏: —Ä–µ—à–∞–µ—Ç—Å—è –∫–∞–∫ –∑–∞–¥–∞—á–∞ –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è.',
      },
      en: {
        label: 'SVM',
        description: 'Support Vector Machine ‚Äî finds optimal hyperplane to separate classes.',
        keyPoints: [
          'üìè Maximizes margin between classes',
          'üîÆ Kernel trick for nonlinear boundaries',
          'üí™ Works in high dimensions',
          'üìä Good for small datasets',
        ],
        howItWorks: 'Goal: find hyperplane maximally distant from nearest points of both classes (support vectors). Margin = distance to nearest points √ó 2. Kernel trick: projects data to higher-dimensional space where linearly separable. Kernel examples: RBF (radial), polynomial. Soft margin: allows errors for non-separable data. Mathematically: solved as quadratic programming problem.',
      },
    },
  },
  {
    id: 'kmeans',
    position: { x: 30, y: 520 },
    type: 'custom',
    data: {
      emoji: 'üéØ',
      level: 'algorithm',
      ru: {
        label: 'K-Means',
        description: '–ê–ª–≥–æ—Ä–∏—Ç–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏, –≥—Ä—É–ø–ø–∏—Ä—É—é—â–∏–π –¥–∞–Ω–Ω—ã–µ –≤ K –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –ø–æ –±–ª–∏–∑–æ—Å—Ç–∏ –∫ —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞–º.',
        keyPoints: [
          'üî¢ K ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–∑–∞–¥–∞—ë—Ç—Å—è)',
          'üîÑ –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ: –Ω–∞–∑–Ω–∞—á–∏—Ç—å ‚Üí –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å —Ü–µ–Ω—Ç—Ä—ã',
          'üìè –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç –≤–Ω—É—Ç—Ä–∏–∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ',
          '‚ö° –ë—ã—Å—Ç—Ä—ã–π, –Ω–æ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –Ω–∞—á–∞–ª—å–Ω—ã–º —Ç–æ—á–∫–∞–º',
        ],
        howItWorks: '–ü—Ä–µ–¥—Å—Ç–∞–≤—å: —É —Ç–µ–±—è 100 –∫–ª–∏–µ–Ω—Ç–æ–≤ –∏ —Ç—ã —Ö–æ—á–µ—à—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å –∏—Ö –Ω–∞ 3 –≥—Ä—É–ø–ø—ã –ø–æ –ø–æ–≤–µ–¥–µ–Ω–∏—é.\n\n1Ô∏è‚É£ –°—Ç–∞–≤–∏–º 3 "—Ñ–ª–∞–∂–∫–∞" (—Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞) –≤ —Å–ª—É—á–∞–π–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö\n2Ô∏è‚É£ –ö–∞–∂–¥—ã–π –∫–ª–∏–µ–Ω—Ç –∏–¥—ë—Ç –∫ –±–ª–∏–∂–∞–π—à–µ–º—É —Ñ–ª–∞–∂–∫—É ‚Äî —Ç–∞–∫ –æ–±—Ä–∞–∑—É—é—Ç—Å—è –≥—Ä—É–ø–ø—ã\n3Ô∏è‚É£ –ü–µ—Ä–µ–¥–≤–∏–≥–∞–µ–º —Ñ–ª–∞–∂–æ–∫ –≤ —Ü–µ–Ω—Ç—Ä —Å–≤–æ–µ–π –≥—Ä—É–ø–ø—ã\n4Ô∏è‚É£ –ü–æ–≤—Ç–æ—Ä—è–µ–º —à–∞–≥–∏ 2-3 –ø–æ–∫–∞ —Ñ–ª–∞–∂–∫–∏ –Ω–µ –ø–µ—Ä–µ—Å—Ç–∞–Ω—É—Ç –¥–≤–∏–≥–∞—Ç—å—Å—è\n\n–í–∞–∂–Ω–æ:\n‚Ä¢ K (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä—É–ø–ø) –∑–∞–¥–∞—ë–º —Å–∞–º–∏ ‚Äî –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–µ —É–≥–∞–¥—ã–≤–∞–µ—Ç\n‚Ä¢ –ù–∞—á–∞–ª—å–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ —Ñ–ª–∞–∂–∫–æ–≤ –≤–ª–∏—è—é—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –†–∞–∑–Ω—ã–π —Å—Ç–∞—Ä—Ç = —Ä–∞–∑–Ω—ã–µ –≥—Ä—É–ø–ø—ã\n‚Ä¢ Elbow method: –ø—Ä–æ–±—É–µ–º K=2,3,4... –∏ —Å–º–æ—Ç—Ä–∏–º –≥–¥–µ –æ—à–∏–±–∫–∞ —Ä–µ–∑–∫–æ –ø–µ—Ä–µ—Å—Ç–∞—ë—Ç –ø–∞–¥–∞—Ç—å',
      },
      en: {
        label: 'K-Means',
        description: 'Clustering algorithm grouping data into K clusters by proximity to centroids.',
        keyPoints: [
          'üî¢ K ‚Äî number of clusters (specified)',
          'üîÑ Iterative: assign ‚Üí recalculate centers',
          'üìè Minimizes within-cluster distance',
          '‚ö° Fast, but sensitive to initial points',
        ],
        howItWorks: 'Imagine: you have 100 customers and want to split them into 3 groups by behavior.\n\n1Ô∏è‚É£ Place 3 "flags" (centroids) at random locations\n2Ô∏è‚É£ Each customer goes to nearest flag ‚Äî this forms groups\n3Ô∏è‚É£ Move each flag to center of its group\n4Ô∏è‚É£ Repeat steps 2-3 until flags stop moving\n\nImportant:\n‚Ä¢ K (number of groups) we set ourselves ‚Äî algorithm doesn\'t guess\n‚Ä¢ Starting positions affect result! Different start = different groups\n‚Ä¢ Elbow method: try K=2,3,4... and see where error stops dropping sharply',
      },
    },
  },
  {
    id: 'pca',
    position: { x: 210, y: 520 },
    type: 'custom',
    data: {
      emoji: 'üìâ',
      level: 'algorithm',
      ru: {
        label: 'PCA',
        description: 'Principal Component Analysis ‚Äî —Å–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –º–∞–∫—Å–∏–º—É–º–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.',
        keyPoints: [
          'üìä –ù–∞—Ö–æ–¥–∏—Ç –≥–ª–∞–≤–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤–∞—Ä–∏–∞—Ü–∏–∏',
          'üîΩ –ü—Ä–æ–µ–∫—Ü–∏—è –Ω–∞ –º–µ–Ω—å—à–µ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ',
          'üìà –°–æ—Ö—Ä–∞–Ω—è–µ—Ç % –æ–±—ä—è—Å–Ω—ë–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏',
          'üëÅÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏',
        ],
        howItWorks: '–ò–¥–µ—è: –Ω–∞–π—Ç–∏ –Ω–æ–≤—ã–µ –æ—Å–∏ (–≥–ª–∞–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã) –ø–æ –∫–æ—Ç–æ—Ä—ã–º –¥–∞–Ω–Ω—ã–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ "—Ä–∞—Å—Ç—è–Ω—É—Ç—ã". –ê–ª–≥–æ—Ä–∏—Ç–º: 1) –¶–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (–≤—ã—á–µ—Å—Ç—å —Å—Ä–µ–¥–Ω–µ–µ) 2) –í—ã—á–∏—Å–ª–∏—Ç—å –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É 3) –ù–∞–π—Ç–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –∏ –∑–Ω–∞—á–µ–Ω–∏—è 4) –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π 5) –í—ã–±—Ä–∞—Ç—å —Ç–æ–ø-K –∫–æ–º–ø–æ–Ω–µ–Ω—Ç 6) –ü—Ä–æ–µ—Ü–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ. –ü–µ—Ä–≤–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –æ–±—ä—è—Å–Ω—è–µ—Ç –º–∞–∫—Å–∏–º—É–º –¥–∏—Å–ø–µ—Ä—Å–∏–∏, –≤—Ç–æ—Ä–∞—è ‚Äî –º–∞–∫—Å–∏–º—É–º –æ—Å—Ç–∞–≤—à–µ–π—Å—è, –∏ —Ç.–¥.',
      },
      en: {
        label: 'PCA',
        description: 'Principal Component Analysis ‚Äî dimensionality reduction preserving maximum information.',
        keyPoints: [
          'üìä Finds main directions of variation',
          'üîΩ Projects to lower dimensions',
          'üìà Preserves % of explained variance',
          'üëÅÔ∏è Used for visualization',
        ],
        howItWorks: 'Idea: find new axes (principal components) along which data is maximally "stretched". Algorithm: 1) Center data (subtract mean) 2) Compute covariance matrix 3) Find eigenvectors and eigenvalues 4) Sort by decreasing eigenvalues 5) Select top-K components 6) Project data. First component explains maximum variance, second ‚Äî maximum of remaining, etc.',
      },
    },
  },
  {
    id: 'qlearning',
    position: { x: 390, y: 400 },
    type: 'custom',
    data: {
      emoji: 'üé∞',
      level: 'algorithm',
      ru: {
        label: 'Q-Learning',
        description: '–ê–ª–≥–æ—Ä–∏—Ç–º RL, –æ–±—É—á–∞—é—â–∏–π —Ñ—É–Ω–∫—Ü–∏—é —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –¥–µ–π—Å—Ç–≤–∏–π –±–µ–∑ –º–æ–¥–µ–ª–∏ —Å—Ä–µ–¥—ã.',
        keyPoints: [
          'üìä Q(s,a) = –æ–∂–∏–¥–∞–µ–º–∞—è –Ω–∞–≥—Ä–∞–¥–∞',
          'üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ –ë–µ–ª–ª–º–∞–Ω–∞',
          'üé≤ Œµ-greedy –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è',
          'üö´ Model-free: –Ω–µ –∑–Ω–∞–µ—Ç –ø—Ä–∞–≤–∏–ª —Å—Ä–µ–¥—ã',
        ],
        howItWorks: 'Q-—Ç–∞–±–ª–∏—Ü–∞ —Ö—Ä–∞–Ω–∏—Ç —Ü–µ–Ω–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è –≤ –∫–∞–∂–¥–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ: Q(s,a) ‚Üê Q(s,a) + Œ±[r + Œ≥¬∑max(Q(s\',a\')) - Q(s,a)], –≥–¥–µ Œ± ‚Äî learning rate, Œ≥ ‚Äî discount factor, r ‚Äî –Ω–∞–≥—Ä–∞–¥–∞, s\' ‚Äî –Ω–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ. Œµ-greedy: —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é Œµ –≤—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ (exploration), –∏–Ω–∞—á–µ –ª—É—á—à–µ–µ –ø–æ Q (exploitation). Deep Q-Network (DQN): –∑–∞–º–µ–Ω—è–µ—Ç —Ç–∞–±–ª–∏—Ü—É –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é –¥–ª—è –±–æ–ª—å—à–∏—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤ —Å–æ—Å—Ç–æ—è–Ω–∏–π.',
      },
      en: {
        label: 'Q-Learning',
        description: 'RL algorithm learning action-value function without environment model.',
        keyPoints: [
          'üìä Q(s,a) = expected reward',
          'üîÑ Updates via Bellman equation',
          'üé≤ Œµ-greedy for exploration',
          'üö´ Model-free: no environment rules',
        ],
        howItWorks: 'Q-table stores value of each action in each state. Update: Q(s,a) ‚Üê Q(s,a) + Œ±[r + Œ≥¬∑max(Q(s\',a\')) - Q(s,a)], where Œ± ‚Äî learning rate, Œ≥ ‚Äî discount factor, r ‚Äî reward, s\' ‚Äî new state. Œµ-greedy: with probability Œµ choose random action (exploration), otherwise best by Q (exploitation). Deep Q-Network (DQN): replaces table with neural network for large state spaces.',
      },
    },
  },

  // ========== ALGORITHM (DL architectures) ==========
  {
    id: 'nn',
    position: { x: 520, y: 260 },
    type: 'custom',
    data: {
      emoji: 'üîÆ',
      level: 'algorithm',
      ru: {
        label: '–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏',
        description: '–ê–ª–≥–æ—Ä–∏—Ç–º –∏–∑ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤, –ø–µ—Ä–µ–¥–∞—é—â–∏—Ö –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É—é—â–∏—Ö —Å–∏–≥–Ω–∞–ª—ã.',
        keyPoints: [
          'üß† –í–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω—ã –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º –º–æ–∑–≥–æ–º',
          '‚ö° –ù–µ–π—Ä–æ–Ω: –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ + –∞–∫—Ç–∏–≤–∞—Ü–∏—è',
          'üîÑ –û–±—É—á–µ–Ω–∏–µ: backpropagation + gradient descent',
          'üèóÔ∏è –°–ª–æ–∏: input ‚Üí hidden ‚Üí output',
        ],
        howItWorks: '–ü—Ä–µ–¥—Å—Ç–∞–≤—å —Å–µ—Ç—å –∫–∞–∫ —Ü–µ–ø–æ—á–∫—É —Ñ–∏–ª—å—Ç—Ä–æ–≤: –≤—Ö–æ–¥ ‚Üí —Ñ–∏–ª—å—Ç—Ä 1 ‚Üí —Ñ–∏–ª—å—Ç—Ä 2 ‚Üí ... ‚Üí –≤—ã—Ö–æ–¥.\n\n–ö–∞–∂–¥—ã–π –Ω–µ–π—Ä–æ–Ω –¥–µ–ª–∞–µ—Ç –ø—Ä–æ—Å—Ç–æ–µ:\n1Ô∏è‚É£ –ë–µ—Ä—ë—Ç –≤—Ö–æ–¥—ã, —É–º–Ω–æ–∂–∞–µ—Ç –Ω–∞ –≤–µ—Å–∞ (w) –∏ —Å–∫–ª–∞–¥—ã–≤–∞–µ—Ç\n2Ô∏è‚É£ –ü—Ä–∏–±–∞–≤–ª—è–µ—Ç —Å–º–µ—â–µ–Ω–∏–µ (b)\n3Ô∏è‚É£ –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç —á–µ—Ä–µ–∑ –∞–∫—Ç–∏–≤–∞—Ü–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä ReLU: –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ ‚Üí 0)\n\n–û–±—É—á–µ–Ω–∏–µ (backpropagation):\n‚Ä¢ –ü—Ä–æ–≥–æ–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤–ø–µ—Ä—ë–¥, –ø–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç\n‚Ä¢ –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º ‚Äî –ø–æ–ª—É—á–∞–µ–º –æ—à–∏–±–∫—É\n‚Ä¢ –ò–¥—ë–º –Ω–∞–∑–∞–¥ –ø–æ —Å–µ—Ç–∏: "–∫—Ç–æ –≤–∏–Ω–æ–≤–∞—Ç –≤ –æ—à–∏–±–∫–µ?"\n‚Ä¢ –ö–∞–∂–¥—ã–π –≤–µ—Å –Ω–µ–º–Ω–æ–≥–æ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç—Å—è —á—Ç–æ–±—ã —É–º–µ–Ω—å—à–∏—Ç—å –æ—à–∏–±–∫—É\n‚Ä¢ –ü–æ–≤—Ç–æ—Ä—è–µ–º —Ç—ã—Å—è—á–∏ —Ä–∞–∑\n\nüí° –ß–µ–º –±–æ–ª—å—à–µ —Å–ª–æ—ë–≤ ‚Äî —Ç–µ–º —Å–ª–æ–∂–Ω–µ–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –º–æ–∂–µ—Ç –≤—ã—É—á–∏—Ç—å —Å–µ—Ç—å',
      },
      en: {
        label: 'Neural Networks',
        description: 'Algorithm of connected artificial neurons that transmit and transform signals.',
        keyPoints: [
          'üß† Inspired by biological brain',
          '‚ö° Neuron: weighted sum + activation',
          'üîÑ Training: backpropagation + gradient descent',
          'üèóÔ∏è Layers: input ‚Üí hidden ‚Üí output',
        ],
        howItWorks: 'Think of network as a chain of filters: input ‚Üí filter 1 ‚Üí filter 2 ‚Üí ... ‚Üí output.\n\nEach neuron does something simple:\n1Ô∏è‚É£ Takes inputs, multiplies by weights (w), sums them up\n2Ô∏è‚É£ Adds bias (b)\n3Ô∏è‚É£ Passes through activation (e.g. ReLU: negative ‚Üí 0)\n\nTraining (backpropagation):\n‚Ä¢ Run data forward, get answer\n‚Ä¢ Compare with correct one ‚Äî get error\n‚Ä¢ Go backward through network: "who caused the error?"\n‚Ä¢ Each weight adjusted slightly to reduce error\n‚Ä¢ Repeat thousands of times\n\nüí° More layers = more complex patterns network can learn',
      },
    },
  },
  {
    id: 'cnn',
    position: { x: 700, y: 260 },
    type: 'custom',
    data: {
      emoji: 'üëÅÔ∏è',
      level: 'algorithm',
      ru: {
        label: 'CNN',
        description: '–°–≤—ë—Ä—Ç–æ—á–Ω—ã–µ —Å–µ—Ç–∏ ‚Äî –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å —Å–µ—Ç–æ—á–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è).',
        keyPoints: [
          'üî≤ –°–≤—ë—Ä—Ç–∫–∞: —Å–∫–æ–ª—å–∑—è—â–∏–π —Ñ–∏–ª—å—Ç—Ä –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é',
          'üìê Pooling: —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏',
          'üé® –ò–µ—Ä–∞—Ä—Ö–∏—è: –∫—Ä–∞—è ‚Üí —Ñ–æ—Ä–º—ã ‚Üí –æ–±—ä–µ–∫—Ç—ã',
          'üì∏ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ, –¥–µ—Ç–µ–∫—Ü–∏—è',
        ],
        howItWorks: '–°–≤—ë—Ä—Ç–∫–∞: —Ñ–∏–ª—å—Ç—Ä (—è–¥—Ä–æ) 3x3 –∏–ª–∏ 5x5 —Å–∫–æ–ª—å–∑–∏—Ç –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, –≤—ã—á–∏—Å–ª—è—è —Å–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ. –û–¥–∏–Ω —Ñ–∏–ª—å—Ç—Ä = –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫ (–≥—Ä–∞–Ω—å, —Ü–≤–µ—Ç). Stride ‚Äî —à–∞–≥, padding ‚Äî –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü. Pooling (–æ–±—ã—á–Ω–æ max): —É–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä, —Å–æ—Ö—Ä–∞–Ω—è—è –≥–ª–∞–≤–Ω–æ–µ. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: [Conv‚ÜíReLU‚ÜíPool] √ó N ‚Üí Flatten ‚Üí Dense. –ü—Ä–∏–º–µ—Ä—ã: LeNet (1998), AlexNet (2012), VGG, ResNet (skip connections –¥–ª—è –æ—á–µ–Ω—å –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç–µ–π).',
      },
      en: {
        label: 'CNN',
        description: 'Convolutional networks ‚Äî algorithm for processing grid-structured data (images).',
        keyPoints: [
          'üî≤ Convolution: sliding filter over image',
          'üìê Pooling: dimensionality reduction',
          'üé® Hierarchy: edges ‚Üí shapes ‚Üí objects',
          'üì∏ Uses: recognition, detection',
        ],
        howItWorks: 'Convolution: filter (kernel) 3x3 or 5x5 slides over image, computing dot product. One filter = one feature (edge, color). Stride ‚Äî step, padding ‚Äî adding borders. Pooling (usually max): reduces size, preserving main info. Architecture: [Conv‚ÜíReLU‚ÜíPool] √ó N ‚Üí Flatten ‚Üí Dense. Examples: LeNet (1998), AlexNet (2012), VGG, ResNet (skip connections for very deep networks).',
      },
    },
  },
  {
    id: 'rnn',
    position: { x: 520, y: 400 },
    type: 'custom',
    data: {
      emoji: 'üîÅ',
      level: 'algorithm',
      ru: {
        label: 'RNN',
        description: '–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏ ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, —Å–æ—Ö—Ä–∞–Ω—è—è "–ø–∞–º—è—Ç—å" –æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —à–∞–≥–∞—Ö.',
        keyPoints: [
          'üîÑ –û–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —Å–ª–æ–π –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ',
          'üí≠ Hidden state —Ö—Ä–∞–Ω–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ—à–ª–æ–º',
          'üìù –î–ª—è —Ç–µ–∫—Å—Ç–∞, –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤, –º—É–∑—ã–∫–∏',
          '‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–∞: vanishing gradient –Ω–∞ –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è—Ö',
        ],
        howItWorks: '–ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ t: h‚Çú = tanh(W‚Çï‚Çï¬∑h‚Çú‚Çã‚ÇÅ + W‚Çì‚Çï¬∑x‚Çú), –≥–¥–µ h ‚Äî hidden state, x ‚Äî –≤—Ö–æ–¥. –í–µ—Å–∞ W –æ–±—â–∏–µ –¥–ª—è –≤—Å–µ—Ö —à–∞–≥–æ–≤ (weight sharing). –ü—Ä–æ–±–ª–µ–º–∞ vanishing gradient: –ø—Ä–∏ backprop —á–µ—Ä–µ–∑ –º–Ω–æ–≥–æ —à–∞–≥–æ–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã —É–º–µ–Ω—å—à–∞—é—Ç—Å—è —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ ‚Üí —Å–µ—Ç—å –Ω–µ —É—á–∏—Ç—Å—è –Ω–∞ –¥–∞–ª—å–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è—Ö. –†–µ—à–µ–Ω–∏—è: LSTM –∏ GRU –¥–æ–±–∞–≤–ª—è—é—Ç "–≤–æ—Ä–æ—Ç–∞" –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –ø–æ—Ç–æ–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. Bidirectional RNN: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã.',
      },
      en: {
        label: 'RNN',
        description: 'Recurrent networks ‚Äî process sequences, maintaining "memory" of previous steps.',
        keyPoints: [
          'üîÑ Same layer applied at each step',
          'üí≠ Hidden state stores past information',
          'üìù For text, time series, music',
          '‚ö†Ô∏è Problem: vanishing gradient on long sequences',
        ],
        howItWorks: 'At each step t: h‚Çú = tanh(W‚Çï‚Çï¬∑h‚Çú‚Çã‚ÇÅ + W‚Çì‚Çï¬∑x‚Çú), where h ‚Äî hidden state, x ‚Äî input. Weights W shared across all steps (weight sharing). Vanishing gradient problem: during backprop through many steps gradients decrease exponentially ‚Üí network doesn\'t learn long dependencies. Solutions: LSTM and GRU add "gates" to control information flow. Bidirectional RNN: processes sequence in both directions.',
      },
    },
  },
  {
    id: 'lstm',
    position: { x: 520, y: 520 },
    type: 'custom',
    data: {
      emoji: 'üß†',
      level: 'algorithm',
      ru: {
        label: 'LSTM',
        description: 'Long Short-Term Memory ‚Äî RNN —Å –≤–æ—Ä–æ—Ç–∞–º–∏, —Ä–µ—à–∞—é—â–∞—è –ø—Ä–æ–±–ª–µ–º—É –∑–∞—Ç—É—Ö–∞–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤.',
        keyPoints: [
          'üö™ 3 –≤–æ—Ä–æ—Ç: forget, input, output',
          'üì¶ Cell state ‚Äî –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è –ø–∞–º—è—Ç—å',
          'üîó –ú–æ–∂–µ—Ç –ø–æ–º–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ —Å–æ—Ç–Ω–∏ —à–∞–≥–æ–≤',
          'üìà –°—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è seq2seq –¥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤',
        ],
        howItWorks: '–¢—Ä–∏ –≤–æ—Ä–æ—Ç (0-1 —á–µ—Ä–µ–∑ sigmoid): Forget gate: f‚Çú = œÉ(Wf¬∑[h‚Çú‚Çã‚ÇÅ,x‚Çú]) ‚Äî —á—Ç–æ –∑–∞–±—ã—Ç—å –∏–∑ cell state. Input gate: i‚Çú = œÉ(Wi¬∑[h‚Çú‚Çã‚ÇÅ,x‚Çú]) ‚Äî —á—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤–æ–≥–æ. Output gate: o‚Çú = œÉ(Wo¬∑[h‚Çú‚Çã‚ÇÅ,x‚Çú]) ‚Äî —á—Ç–æ –≤—ã–≤–µ—Å—Ç–∏. Cell state –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è: C‚Çú = f‚Çú‚äôC‚Çú‚Çã‚ÇÅ + i‚Çú‚äôtanh(Wc¬∑[h‚Çú‚Çã‚ÇÅ,x‚Çú]). –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø—Ä–æ—Ç–µ–∫–∞—é—Ç —á–µ—Ä–µ–∑ cell state –±–µ–∑ –∑–∞—Ç—É—Ö–∞–Ω–∏—è. GRU ‚Äî —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å 2 –≤–æ—Ä–æ—Ç–∞–º–∏.',
      },
      en: {
        label: 'LSTM',
        description: 'Long Short-Term Memory ‚Äî RNN with gates solving vanishing gradient problem.',
        keyPoints: [
          'üö™ 3 gates: forget, input, output',
          'üì¶ Cell state ‚Äî long-term memory',
          'üîó Can remember information for hundreds of steps',
          'üìà Standard for seq2seq before transformers',
        ],
        howItWorks: 'Three gates (0-1 via sigmoid): Forget gate: f‚Çú = œÉ(Wf¬∑[h‚Çú‚Çã‚ÇÅ,x‚Çú]) ‚Äî what to forget from cell state. Input gate: i‚Çú = œÉ(Wi¬∑[h‚Çú‚Çã‚ÇÅ,x‚Çú]) ‚Äî what new to add. Output gate: o‚Çú = œÉ(Wo¬∑[h‚Çú‚Çã‚ÇÅ,x‚Çú]) ‚Äî what to output. Cell state updates: C‚Çú = f‚Çú‚äôC‚Çú‚Çã‚ÇÅ + i‚Çú‚äôtanh(Wc¬∑[h‚Çú‚Çã‚ÇÅ,x‚Çú]). Gradients flow through cell state without vanishing. GRU ‚Äî simplified version with 2 gates.',
      },
    },
  },
  {
    id: 'transformer',
    position: { x: 700, y: 400 },
    type: 'custom',
    data: {
      emoji: '‚ö°',
      level: 'algorithm',
      ru: {
        label: 'Transformer',
        description: '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–∞ –º–µ—Ö–∞–Ω–∏–∑–º–µ –≤–Ω–∏–º–∞–Ω–∏—è, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—â–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ.',
        keyPoints: [
          'üëÄ Self-attention: –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω "–≤–∏–¥–∏—Ç" –≤—Å–µ –¥—Ä—É–≥–∏–µ',
          '‚ö° –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (vs RNN –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ)',
          'üìç Positional encoding –¥–ª—è –ø–æ—Ä—è–¥–∫–∞',
          'üìÑ –°—Ç–∞—Ç—å—è "Attention Is All You Need" (2017)',
        ],
        howItWorks: 'Self-attention: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –≤—ã—á–∏—Å–ª—è–µ–º Query, Key, Value —á–µ—Ä–µ–∑ –ª–∏–Ω–µ–π–Ω—ã–µ –ø—Ä–æ–µ–∫—Ü–∏–∏. Attention(Q,K,V) = softmax(QK·µÄ/‚àöd)V. –ö–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω –ø–æ–ª—É—á–∞–µ—Ç –≤–∑–≤–µ—à–µ–Ω–Ω—É—é —Å—É–º–º—É –≤—Å–µ—Ö Value, –≤–µ—Å–∞ = —Å—Ö–æ–¥—Å—Ç–≤–æ Query –∏ Key. Multi-head: –Ω–µ—Å–∫–æ–ª—å–∫–æ attention –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ ‚Üí —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã —Å–≤—è–∑–µ–π. Encoder: self-attention + feed-forward. Decoder: masked self-attention (–≤–∏–¥–∏—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª–æ–µ) + cross-attention –∫ encoder. Positional encoding –¥–æ–±–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∑–∏—Ü–∏–∏.',
      },
      en: {
        label: 'Transformer',
        description: 'Architecture based on attention mechanism, processing sequences in parallel.',
        keyPoints: [
          'üëÄ Self-attention: each token "sees" all others',
          '‚ö° Parallel processing (vs RNN sequential)',
          'üìç Positional encoding for order',
          'üìÑ Paper "Attention Is All You Need" (2017)',
        ],
        howItWorks: 'Self-attention: for each token compute Query, Key, Value via linear projections. Attention(Q,K,V) = softmax(QK·µÄ/‚àöd)V. Each token gets weighted sum of all Values, weights = Query-Key similarity. Multi-head: several attention in parallel ‚Üí different relationship types. Encoder: self-attention + feed-forward. Decoder: masked self-attention (sees only past) + cross-attention to encoder. Positional encoding adds position information.',
      },
    },
  },
  {
    id: 'attention',
    position: { x: 700, y: 520 },
    type: 'custom',
    data: {
      emoji: 'üëÅÔ∏è',
      level: 'algorithm',
      ru: {
        label: 'Attention',
        description: '–ú–µ—Ö–∞–Ω–∏–∑–º, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –º–æ–¥–µ–ª–∏ —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞—Å—Ç—è—Ö –≤—Ö–æ–¥–∞.',
        keyPoints: [
          'üéØ –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –≤–µ—Å–∞ –≤–º–µ—Å—Ç–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö',
          'üîó –°–≤—è–∑—ã–≤–∞–µ—Ç –ª—é–±—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞–ø—Ä—è–º—É—é',
          'üìä Softmax –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤–µ—Å–∞ –≤ —Å—É–º–º—É = 1',
          'üí° –ò–∑–Ω–∞—á–∞–ª—å–Ω–æ –¥–ª—è seq2seq translation',
        ],
        howItWorks: '–ü—Ä–µ–¥—Å—Ç–∞–≤—å: —Ç—ã –ø–µ—Ä–µ–≤–æ–¥–∏—à—å "The black cat sat" –Ω–∞ —Ä—É—Å—Å–∫–∏–π. –ö–æ–≥–¥–∞ –ø–∏—à–µ—à—å —Å–ª–æ–≤–æ "–∫–æ—Ç", –Ω–∞ –∫–∞–∫–æ–µ –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ —Å–ª–æ–≤–æ —Å–º–æ—Ç—Ä–∏—à—å? –ö–æ–Ω–µ—á–Ω–æ –Ω–∞ "cat"! –ê –Ω–∞ "The" –ø–æ—á—Ç–∏ –Ω–µ —Å–º–æ—Ç—Ä–∏—à—å.\n\nAttention –¥–µ–ª–∞–µ—Ç —Ç–æ –∂–µ —Å–∞–º–æ–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:\n1Ô∏è‚É£ –î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞ –≤—ã—á–∏—Å–ª—è–µ–º "–≤–∞–∂–Ω–æ—Å—Ç—å" –∫–∞–∂–¥–æ–≥–æ –≤—Ö–æ–¥–Ω–æ–≥–æ\n2Ô∏è‚É£ –í–∞–∂–Ω–æ—Å—Ç—å = –Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ —Å–≤—è–∑–∞–Ω—ã (—á–µ—Ä–µ–∑ Query-Key —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ)\n3Ô∏è‚É£ Softmax –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã (—Å—É–º–º–∞ = 100%)\n4Ô∏è‚É£ –ò—Ç–æ–≥–æ–≤—ã–π –≤–µ–∫—Ç–æ—Ä = —Å–º–µ—Å—å –≤—Ö–æ–¥–Ω—ã—Ö —Å–ª–æ–≤ –ø–æ —ç—Ç–∏–º –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º\n\n–¢–µ—Ä–º–∏–Ω—ã:\n‚Ä¢ Query ‚Äî "—á—Ç–æ –∏—â–µ–º" (—Ç–µ–∫—É—â–µ–µ –≤—ã—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ)\n‚Ä¢ Key ‚Äî "—á—Ç–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º" (–≤—Å–µ –≤—Ö–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞)\n‚Ä¢ Value ‚Äî "—á—Ç–æ –±–µ—Ä—ë–º" (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö —Å–ª–æ–≤)',
      },
      en: {
        label: 'Attention',
        description: 'Mechanism allowing model to focus on relevant parts of input.',
        keyPoints: [
          'üéØ Dynamic weights instead of fixed',
          'üîó Connects any positions directly',
          'üìä Softmax normalizes weights to sum = 1',
          'üí° Originally for seq2seq translation',
        ],
        howItWorks: 'Imagine: you\'re translating "The black cat sat" to French. When writing "chat", which English word do you look at? Of course "cat"! You barely look at "The".\n\nAttention does the same automatically:\n1Ô∏è‚É£ For each output word, compute "importance" of each input word\n2Ô∏è‚É£ Importance = how related words are (via Query-Key comparison)\n3Ô∏è‚É£ Softmax turns importances into percentages (sum = 100%)\n4Ô∏è‚É£ Final vector = mix of input words by these percentages\n\nTerms:\n‚Ä¢ Query ‚Äî "what we\'re looking for" (current output word)\n‚Ä¢ Key ‚Äî "what we offer" (all input words)\n‚Ä¢ Value ‚Äî "what we take" (information from input words)',
      },
    },
  },
  {
    id: 'gan',
    position: { x: 880, y: 400 },
    type: 'custom',
    data: {
      emoji: 'üé≠',
      level: 'algorithm',
      ru: {
        label: 'GAN',
        description: 'Generative Adversarial Network ‚Äî –¥–≤–µ —Å–µ—Ç–∏ —Å–æ—Ä–µ–≤–Ω—É—é—Ç—Å—è: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–æ–∑–¥–∞—ë—Ç, –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –ø—Ä–æ–≤–µ—Ä—è–µ—Ç.',
        keyPoints: [
          'üé® Generator —Å–æ–∑–¥–∞—ë—Ç —Ñ–µ–π–∫–∏ –∏–∑ —à—É–º–∞',
          'üîç Discriminator –æ—Ç–ª–∏—á–∞–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–µ –æ—Ç —Ñ–µ–π–∫–∞',
          '‚öîÔ∏è –ò–≥—Ä–∞ —Å –Ω—É–ª–µ–≤–æ–π —Å—É–º–º–æ–π',
          'üñºÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, deepfakes',
        ],
        howItWorks: 'Generator G(z) –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º z –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. Discriminator D(x) –≤—ã–¥–∞—ë—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —á—Ç–æ x —Ä–µ–∞–ª—å–Ω–æ–µ. –û–±—É—á–µ–Ω–∏–µ: D —É—á–∏—Ç—Å—è –æ—Ç–ª–∏—á–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –æ—Ç G(z), G —É—á–∏—Ç—Å—è –æ–±–º–∞–Ω—ã–≤–∞—Ç—å D. Minimax –∏–≥—Ä–∞: minG maxD [E[log D(x)] + E[log(1-D(G(z)))]]. –ü—Ä–æ–±–ª–µ–º—ã: mode collapse (G –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ), –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è. –£–ª—É—á—à–µ–Ω–∏—è: DCGAN, WGAN (Wasserstein distance), StyleGAN (–∫–æ–Ω—Ç—Ä–æ–ª—å —Å—Ç–∏–ª—è).',
      },
      en: {
        label: 'GAN',
        description: 'Generative Adversarial Network ‚Äî two networks compete: generator creates, discriminator verifies.',
        keyPoints: [
          'üé® Generator creates fakes from noise',
          'üîç Discriminator distinguishes real from fake',
          '‚öîÔ∏è Zero-sum game',
          'üñºÔ∏è Image generation, deepfakes',
        ],
        howItWorks: 'Generator G(z) transforms random noise z into image. Discriminator D(x) outputs probability x is real. Training: D learns to distinguish real from G(z), G learns to fool D. Minimax game: minG maxD [E[log D(x)] + E[log(1-D(G(z)))]]. Problems: mode collapse (G generates same thing), training instability. Improvements: DCGAN, WGAN (Wasserstein distance), StyleGAN (style control).',
      },
    },
  },
  {
    id: 'vae',
    position: { x: 880, y: 520 },
    type: 'custom',
    data: {
      emoji: 'üé≤',
      level: 'algorithm',
      ru: {
        label: 'VAE',
        description: 'Variational Autoencoder ‚Äî —É—á–∏—Ç —Å–∂–∞—Ç–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö + –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–µ.',
        keyPoints: [
          'üì¶ Encoder —Å–∂–∏–º–∞–µ—Ç –≤ latent space',
          'üì§ Decoder –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑ latent',
          'üéØ Latent = —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (Œº, œÉ)',
          'üîÄ –°—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏',
        ],
        howItWorks: 'Encoder –≤—ã–¥–∞—ë—Ç –Ω–µ —Ç–æ—á–∫—É, –∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: Œº (—Å—Ä–µ–¥–Ω–µ–µ) –∏ œÉ (–¥–∏—Å–ø–µ—Ä—Å–∏—è). Reparametrization trick: z = Œº + œÉ¬∑Œµ, –≥–¥–µ Œµ ~ N(0,1) ‚Äî –ø–æ–∑–≤–æ–ª—è–µ—Ç backprop. Decoder –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç x –∏–∑ z. Loss = reconstruction_loss + KL_divergence(q(z|x) || p(z)). KL –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç latent –±—ã—Ç—å –±–ª–∏–∑–∫–∏–º –∫ N(0,1) ‚Üí –º–æ–∂–Ω–æ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å –∏–∑ N(0,1) –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. Latent space –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π ‚Üí –º–æ–∂–Ω–æ –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä–æ–≤–∞—Ç—å –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏.',
      },
      en: {
        label: 'VAE',
        description: 'Variational Autoencoder ‚Äî learns compressed representation + generates new samples.',
        keyPoints: [
          'üì¶ Encoder compresses to latent space',
          'üì§ Decoder reconstructs from latent',
          'üéØ Latent = distribution (Œº, œÉ)',
          'üîÄ Sampling for generation',
        ],
        howItWorks: 'Encoder outputs not point but distribution: Œº (mean) and œÉ (variance). Reparametrization trick: z = Œº + œÉ¬∑Œµ, where Œµ ~ N(0,1) ‚Äî enables backprop. Decoder reconstructs x from z. Loss = reconstruction_loss + KL_divergence(q(z|x) || p(z)). KL forces latent to be close to N(0,1) ‚Üí can sample from N(0,1) for generation. Latent space is continuous ‚Üí can interpolate between objects.',
      },
    },
  },
  {
    id: 'diffusion',
    position: { x: 1060, y: 400 },
    type: 'custom',
    data: {
      emoji: 'üå´Ô∏è',
      level: 'algorithm',
      ru: {
        label: 'Diffusion',
        description: '–î–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ ‚Äî —É—á–∞—Ç—Å—è –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–±–∏—Ä–∞—Ç—å —à—É–º, –≥–µ–Ω–µ—Ä–∏—Ä—É—è –¥–∞–Ω–Ω—ã–µ –∏–∑ —á–∏—Å—Ç–æ–≥–æ —à—É–º–∞.',
        keyPoints: [
          '‚û°Ô∏è Forward: –¥–æ–±–∞–≤–ª—è–µ–º —à—É–º —à–∞–≥ –∑–∞ —à–∞–≥–æ–º',
          '‚¨ÖÔ∏è Reverse: —É–±–∏—Ä–∞–µ–º —à—É–º (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è)',
          'üé® SOTA –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π',
          'üñºÔ∏è Stable Diffusion, DALL-E, Midjourney',
        ],
        howItWorks: 'Forward process: x‚ÇÄ ‚Üí x‚ÇÅ ‚Üí ... ‚Üí x‚Çú, –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –¥–æ–±–∞–≤–ª—è–µ–º –≥–∞—É—Å—Å–æ–≤—Å–∫–∏–π —à—É–º, –≤ –∫–æ–Ω—Ü–µ ‚Äî —á–∏—Å—Ç—ã–π —à—É–º. Reverse process: –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —à—É–º –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–π –Ω–∞ —à–∞–≥–µ t, –∏ –≤—ã—á–∏—Ç–∞–µ—Ç –µ–≥–æ: x‚Çú ‚Üí x‚Çú‚Çã‚ÇÅ ‚Üí ... ‚Üí x‚ÇÄ. –û–±—É—á–µ–Ω–∏–µ: –±–µ—Ä—ë–º —á–∏—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –¥–æ–±–∞–≤–ª—è–µ–º —à—É–º, –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —ç—Ç–æ—Ç —à—É–º. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è: –Ω–∞—á–∏–Ω–∞–µ–º —Å —á–∏—Å—Ç–æ–≥–æ —à—É–º–∞, –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ —É–±–∏—Ä–∞–µ–º. –£—Å–ª–æ–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è: –¥–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π embedding (CLIP) –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è.',
      },
      en: {
        label: 'Diffusion',
        description: 'Diffusion models ‚Äî learn to gradually remove noise, generating data from pure noise.',
        keyPoints: [
          '‚û°Ô∏è Forward: add noise step by step',
          '‚¨ÖÔ∏è Reverse: remove noise (generation)',
          'üé® SOTA for image generation',
          'üñºÔ∏è Stable Diffusion, DALL-E, Midjourney',
        ],
        howItWorks: 'Forward process: x‚ÇÄ ‚Üí x‚ÇÅ ‚Üí ... ‚Üí x‚Çú, at each step add Gaussian noise, end with pure noise. Reverse process: model learns to predict noise added at step t, and subtracts it: x‚Çú ‚Üí x‚Çú‚Çã‚ÇÅ ‚Üí ... ‚Üí x‚ÇÄ. Training: take clean image, add noise, model predicts this noise. Generation: start from pure noise, iteratively remove. Conditional generation: add text embedding (CLIP) for control.',
      },
    },
  },

  // ========== IMPLEMENTATION (NLP) ==========
  {
    id: 'llm',
    position: { x: 950, y: 260 },
    type: 'custom',
    data: {
      emoji: 'üó£Ô∏è',
      level: 'implementation',
      ru: {
        label: 'LLM',
        description: '–ë–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ ‚Äî –º–∞—Å—à—Ç–∞–±–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –æ–±—É—á–µ–Ω–Ω—ã–µ –Ω–∞ –æ–≥—Ä–æ–º–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ—Ä–ø—É—Å–∞—Ö.',
        keyPoints: [
          'üìè –†–∞–∑–º–µ—Ä: –º–∏–ª–ª–∏–∞—Ä–¥—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (GPT-4: —Å–æ—Ç–Ω–∏ –º–ª—Ä–¥+)',
          'üìö –û–±—É—á–µ–Ω–∏–µ: –≤–µ—Å—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç + –∫–Ω–∏–≥–∏ + –∫–æ–¥',
          'üé≠ Emergent abilities –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏',
          'üîß –ü—Ä–∏–º–µ—Ä—ã: GPT-4, Claude, Gemini, LLaMA',
        ],
        howItWorks: '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: decoder-only transformer. –û–±—É—á–µ–Ω–∏–µ: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ (causal LM). –î–∞—Ç–∞—Å–µ—Ç: —Ç—Ä–∏–ª–ª–∏–æ–Ω—ã —Ç–æ–∫–µ–Ω–æ–≤ —Ç–µ–∫—Å—Ç–∞. Scaling laws: –±–æ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ + –¥–∞–Ω–Ω—ã—Ö = –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ. Emergent abilities: –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∞ –ø–æ—è–≤–ª—è—é—Ç—Å—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –±—ã–ª–æ (in-context learning, reasoning). Fine-tuning: RLHF (–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è—Ö) –¥–ª—è —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º. Inference: –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ–∫–µ–Ω –∑–∞ —Ç–æ–∫–µ–Ω–æ–º.',
      },
      en: {
        label: 'LLM',
        description: 'Large Language Models ‚Äî massive transformers trained on huge text corpora.',
        keyPoints: [
          'üìè Size: billions of parameters (GPT-4: —Å–æ—Ç–Ω–∏ –º–ª—Ä–¥+)',
          'üìö Training: entire internet + books + code',
          'üé≠ Emergent abilities at scale',
          'üîß Examples: GPT-4, Claude, Gemini, LLaMA',
        ],
        howItWorks: 'Architecture: decoder-only transformer. Training: next token prediction (causal LM). Dataset: trillions of text tokens. Scaling laws: more parameters + data = better quality. Emergent abilities: at certain scale new capabilities appear (in-context learning, reasoning). Fine-tuning: RLHF (learning from human preferences) for instruction following. Inference: autoregressive generation token by token.',
      },
    },
  },
  {
    id: 'embeddings',
    position: { x: 1130, y: 260 },
    type: 'custom',
    data: {
      emoji: 'üìê',
      level: 'implementation',
      ru: {
        label: 'Embeddings',
        description: '–í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è ‚Äî —Å–ª–æ–≤–∞/—Ç–µ–∫—Å—Ç—ã –∫–∞–∫ —Ç–æ—á–∫–∏ –≤ –º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ.',
        keyPoints: [
          'üìä –í–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (768, 1536...)',
          'üìè –ü–æ—Ö–æ–∂–∏–µ –ø–æ–Ω—è—Ç–∏—è = –±–ª–∏–∑–∫–∏–µ –≤–µ–∫—Ç–æ—Ä—ã',
          '‚ûï –ê—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞: king - man + woman ‚âà queen',
          'üîç –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: –ø–æ–∏—Å–∫, RAG, –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è',
        ],
        howItWorks: 'Word2Vec: –æ–±—É—á–∞–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Å–ª–æ–≤–æ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (CBOW) –∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ —Å–ª–æ–≤—É (Skip-gram). Sentence embeddings: —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (SBERT). –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ: cos(a,b) = (a¬∑b)/(|a||b|) ‚Äî –º–µ—Ä–∞ –±–ª–∏–∑–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ RAG: —Ç–µ–∫—Å—Ç ‚Üí embedding ‚Üí –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –≤ –±–∞–∑–µ ‚Üí –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM. OpenAI, Cohere, Voyage –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç embedding API. –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ —Å–∫–æ—Ä–æ—Å—Ç—å—é.',
      },
      en: {
        label: 'Embeddings',
        description: 'Vector representations ‚Äî words/texts as points in multidimensional space.',
        keyPoints: [
          'üìä Fixed dimension vector (768, 1536...)',
          'üìè Similar concepts = nearby vectors',
          '‚ûï Arithmetic: king - man + woman ‚âà queen',
          'üîç Uses: search, RAG, clustering',
        ],
        howItWorks: 'Word2Vec: learns to predict word from context (CBOW) or context from word (Skip-gram). Sentence embeddings: average tokens or specialized model (SBERT). Cosine similarity: cos(a,b) = (a¬∑b)/(|a||b|) ‚Äî vector closeness measure. RAG application: text ‚Üí embedding ‚Üí search similar in database ‚Üí context for LLM. OpenAI, Cohere, Voyage provide embedding APIs. Dimensionality: tradeoff between quality and speed.',
      },
    },
  },
  {
    id: 'tokenization',
    position: { x: 1130, y: 380 },
    type: 'custom',
    data: {
      emoji: '‚úÇÔ∏è',
      level: 'implementation',
      ru: {
        label: '–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è',
        description: '–†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ç–æ–∫–µ–Ω—ã (–µ–¥–∏–Ω–∏—Ü—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏).',
        keyPoints: [
          '‚úÇÔ∏è –¢–µ–∫—Å—Ç ‚Üí —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ (subwords)',
          'üìñ –°–ª–æ–≤–∞—Ä—å: 30k-100k —Ç–æ–∫–µ–Ω–æ–≤',
          'üî§ BPE, WordPiece, SentencePiece –∞–ª–≥–æ—Ä–∏—Ç–º—ã',
          'üí∞ –í–ª–∏—è–µ—Ç –Ω–∞ —Å—Ç–æ–∏–º–æ—Å—Ç—å API ($/1M tokens)',
        ],
        howItWorks: 'BPE (Byte Pair Encoding): –Ω–∞—á–∏–Ω–∞–µ—Ç —Å —Å–∏–º–≤–æ–ª–æ–≤, –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ –ø–∞—Ä—ã. "tokenization" ‚Üí ["token", "ization"] –∏–ª–∏ ["to", "ken", "iz", "ation"]. –†–µ–¥–∫–∏–µ —Å–ª–æ–≤–∞ —Ä–∞–∑–±–∏–≤–∞—é—Ç—Å—è –Ω–∞ –ø–æ–¥—Å–ª–æ–≤–∞, —á–∞—Å—Ç—ã–µ –æ—Å—Ç–∞—é—Ç—Å—è —Ü–µ–ª—ã–º–∏. –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã: [CLS], [SEP], [PAD], <|endoftext|>. –ü—Ä–æ–±–ª–µ–º—ã: —Ä–∞–∑–Ω—ã–µ —è–∑—ã–∫–∏ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É—é—Ç—Å—è –ø–æ-—Ä–∞–∑–Ω–æ–º—É, —ç–º–æ–¥–∑–∏ –∏ –∫–æ–¥ –º–æ–≥—É—Ç –∑–∞–Ω–∏–º–∞—Ç—å –º–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤. tiktoken (OpenAI) ‚Äî –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤.',
      },
      en: {
        label: 'Tokenization',
        description: 'Splitting text into tokens (processing units for the model).',
        keyPoints: [
          '‚úÇÔ∏è Text ‚Üí list of tokens (subwords)',
          'üìñ Vocabulary: 30k-100k tokens',
          'üî§ BPE, WordPiece, SentencePiece algorithms',
          'üí∞ Affects API cost ($/1M tokens)',
        ],
        howItWorks: 'BPE (Byte Pair Encoding): starts with characters, iteratively merges most frequent pairs. "tokenization" ‚Üí ["token", "ization"] or ["to", "ken", "iz", "ation"]. Rare words split into subwords, frequent stay whole. Special tokens: [CLS], [SEP], [PAD], <|endoftext|>. Issues: different languages tokenize differently, emoji and code may take many tokens. tiktoken (OpenAI) ‚Äî library for counting tokens.',
      },
    },
  },

  // ========== COMPUTER VISION BRANCH ==========
  {
    id: 'cv',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üëÅÔ∏è',
      level: 'theory',
      ru: {
        label: '–ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –ó—Ä–µ–Ω–∏–µ',
        description: '–û–±–ª–∞—Å—Ç—å AI, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º –∏–∑–≤–ª–µ–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ–æ.',
        keyPoints: [
          'üì∑ –í—Ö–æ–¥: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–∏–¥–µ–æ, 3D-—Å–∫–∞–Ω—ã',
          'üéØ –ó–∞–¥–∞—á–∏: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, –¥–µ—Ç–µ–∫—Ü–∏—è, —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è',
          'üß† –û—Å–Ω–æ–≤–∞: CNN –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã (ViT)',
          'üöó –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: –∞–≤—Ç–æ–ø–∏–ª–æ—Ç, –º–µ–¥–∏—Ü–∏–Ω–∞, AR/VR',
        ],
        howItWorks: 'CV —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç –ø–∏–∫—Å–µ–ª–∏ –≤ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Å—Ü–µ–Ω—ã. –ü–∞–π–ø–ª–∞–π–Ω: 1) –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è 2) –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Äî CNN —Å–ª–æ–∏ –Ω–∞—Ö–æ–¥—è—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã (–∫—Ä–∞—è ‚Üí —Ñ–æ—Ä–º—ã ‚Üí –æ–±—ä–µ–∫—Ç—ã) 3) –†–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ ‚Äî –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (—á—Ç–æ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ?), –¥–µ—Ç–µ–∫—Ü–∏—è (–≥–¥–µ –æ–±—ä–µ–∫—Ç—ã?), —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è (–∫–∞–∫–æ–π –ø–∏–∫—Å–µ–ª—å —á–µ–º—É –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç?). –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏: ViT (Vision Transformer) –ø—Ä–∏–º–µ–Ω—è–µ—Ç attention –∫ –ø–∞—Ç—á–∞–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. Transfer learning: –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (ImageNet) –¥–æ–æ–±—É—á–∞—é—Ç—Å—è –Ω–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö.',
      },
      en: {
        label: 'Computer Vision',
        description: 'AI field enabling computers to extract information from images and video.',
        keyPoints: [
          'üì∑ Input: images, video, 3D scans',
          'üéØ Tasks: classification, detection, segmentation',
          'üß† Foundation: CNN and transformers (ViT)',
          'üöó Applications: self-driving, medicine, AR/VR',
        ],
        howItWorks: 'CV systems transform pixels into scene understanding. Pipeline: 1) Preprocessing ‚Äî normalization, augmentation 2) Feature extraction ‚Äî CNN layers find patterns (edges ‚Üí shapes ‚Üí objects) 3) Task solving ‚Äî classification (what\'s in image?), detection (where are objects?), segmentation (which pixel belongs to what?). Modern models: ViT (Vision Transformer) applies attention to image patches. Transfer learning: pretrained models (ImageNet) fine-tuned on specific tasks.',
      },
    },
  },
  {
    id: 'obj-detection',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üéØ',
      level: 'method',
      ru: {
        label: '–î–µ—Ç–µ–∫—Ü–∏—è –û–±—ä–µ–∫—Ç–æ–≤',
        description: '–ú–µ—Ç–æ–¥ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –∏ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å –ø–æ–º–æ—â—å—é bounding boxes.',
        keyPoints: [
          'üì¶ –í—ã—Ö–æ–¥: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox + –∫–ª–∞—Å—Å + confidence',
          'üîÑ Two-stage (R-CNN) vs One-stage (YOLO)',
          'üìä –ú–µ—Ç—Ä–∏–∫–∏: mAP, IoU',
          '‚ö° Real-time: YOLO, SSD',
        ],
        howItWorks: 'Two-stage –¥–µ—Ç–µ–∫—Ç–æ—Ä—ã (Faster R-CNN): 1) Region Proposal Network –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç ~2000 —Ä–µ–≥–∏–æ–Ω–æ–≤ 2) CNN –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∫–∞–∂–¥—ã–π —Ä–µ–≥–∏–æ–Ω. –ú–µ–¥–ª–µ–Ω–Ω–æ –Ω–æ —Ç–æ—á–Ω–æ. One-stage –¥–µ—Ç–µ–∫—Ç–æ—Ä—ã (YOLO): –¥–µ–ª—è—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —Å–µ—Ç–∫—É, –∫–∞–∂–¥–∞—è —è—á–µ–π–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç bbox + –∫–ª–∞—Å—Å –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥. –ë—ã—Å—Ç—Ä–æ, –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è real-time. Anchor boxes: –ø—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã bbox —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤. Non-Maximum Suppression: —É–±–∏—Ä–∞–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–¥–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞.',
      },
      en: {
        label: 'Object Detection',
        description: 'Method of finding and localizing objects in images using bounding boxes.',
        keyPoints: [
          'üì¶ Output: bbox coordinates + class + confidence',
          'üîÑ Two-stage (R-CNN) vs One-stage (YOLO)',
          'üìä Metrics: mAP, IoU',
          '‚ö° Real-time: YOLO, SSD',
        ],
        howItWorks: 'Two-stage detectors (Faster R-CNN): 1) Region Proposal Network suggests ~2000 regions 2) CNN classifies each region. Slow but accurate. One-stage detectors (YOLO): divide image into grid, each cell predicts bbox + class in single pass. Fast, suitable for real-time. Anchor boxes: predefined bbox shapes of different sizes. Non-Maximum Suppression: removes duplicate detections of same object.',
      },
    },
  },
  {
    id: 'img-classification',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üè∑Ô∏è',
      level: 'method',
      ru: {
        label: '–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π',
        description: '–ú–µ—Ç–æ–¥ –ø—Ä–∏—Å–≤–æ–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –æ–¥–Ω–æ–π –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–æ–≤.',
        keyPoints: [
          'üéØ Single-label vs Multi-label',
          'üìä Softmax –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∫–ª–∞—Å—Å–æ–≤',
          'üèÜ ImageNet: 1000 –∫–ª–∞—Å—Å–æ–≤, 1.2M –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π',
          'üîÑ Fine-tuning –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π',
        ],
        howItWorks: '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: CNN backbone –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ ‚Üí Global Average Pooling ‚Üí Fully Connected ‚Üí Softmax. –ü—Ä–æ—Ü–µ—Å—Å: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ —Å–≤—ë—Ä—Ç–æ—á–Ω—ã–µ —Å–ª–æ–∏, –∫–∞–∂–¥—ã–π —Å–ª–æ–π –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å—ë –±–æ–ª–µ–µ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏. –§–∏–Ω–∞–ª—å–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç—Å—è –≤ –æ–¥–∏–Ω –∏–∑ –∫–ª–∞—Å—Å–æ–≤. Cross-entropy loss —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å ground truth. Data augmentation (–ø–æ–≤–æ—Ä–æ—Ç—ã, –æ—Ç—Ä–∞–∂–µ–Ω–∏—è, –∫—Ä–æ–ø) —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞.',
      },
      en: {
        label: 'Image Classification',
        description: 'Method of assigning one or more class labels to an image.',
        keyPoints: [
          'üéØ Single-label vs Multi-label',
          'üìä Softmax for class probabilities',
          'üèÜ ImageNet: 1000 classes, 1.2M images',
          'üîÑ Fine-tuning pretrained models',
        ],
        howItWorks: 'Architecture: CNN backbone extracts features ‚Üí Global Average Pooling ‚Üí Fully Connected ‚Üí Softmax. Process: image passes through convolutional layers, each layer extracts increasingly abstract features. Final feature vector classified into one of classes. Cross-entropy loss compares prediction with ground truth. Data augmentation (rotations, flips, crops) increases effective dataset size.',
      },
    },
  },
  {
    id: 'segmentation',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üß©',
      level: 'method',
      ru: {
        label: '–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è',
        description: '–ú–µ—Ç–æ–¥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–∞–∂–¥–æ–≥–æ –ø–∏–∫—Å–µ–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –∫ –æ–±—ä–µ–∫—Ç—É/–∫–ª–∞—Å—Å—É.',
        keyPoints: [
          'üé® Semantic: –∫–ª–∞—Å—Å—ã –±–µ–∑ —Ä–∞–∑–ª–∏—á–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤',
          'üî¢ Instance: –∫–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç –æ—Ç–¥–µ–ª—å–Ω–æ',
          'üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: U-Net, Mask R-CNN, SAM',
          'üè• –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: –º–µ–¥–∏—Ü–∏–Ω–∞, –∞–≤—Ç–æ–ø–∏–ª–æ—Ç, —Ñ–æ—Ç–æ-—Ä–µ–¥–∞–∫—Ç–æ—Ä—ã',
        ],
        howItWorks: 'Semantic segmentation: –∫–∞–∂–¥–æ–º—É –ø–∏–∫—Å–µ–ª—é –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç—Å—è –∫–ª–∞—Å—Å (–Ω–µ–±–æ, –¥–æ—Ä–æ–≥–∞, –º–∞—à–∏–Ω–∞). U-Net –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: encoder —Å–∂–∏–º–∞–µ—Ç ‚Üí decoder –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ, skip connections —Å–æ—Ö—Ä–∞–Ω—è—é—Ç –¥–µ—Ç–∞–ª–∏. Instance segmentation: —Ä–∞–∑–ª–∏—á–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ (–º–∞—à–∏–Ω–∞_1, –º–∞—à–∏–Ω–∞_2). Mask R-CNN: –¥–µ—Ç–µ–∫—Ü–∏—è bbox + –±–∏–Ω–∞—Ä–Ω–∞—è –º–∞—Å–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞. Panoptic: –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç semantic –∏ instance. SAM (Segment Anything): —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å, —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏.',
      },
      en: {
        label: 'Segmentation',
        description: 'Method of classifying each pixel in an image by object/class membership.',
        keyPoints: [
          'üé® Semantic: classes without instance distinction',
          'üî¢ Instance: each object separately',
          'üèóÔ∏è Architectures: U-Net, Mask R-CNN, SAM',
          'üè• Applications: medicine, self-driving, photo editors',
        ],
        howItWorks: 'Semantic segmentation: each pixel assigned a class (sky, road, car). U-Net architecture: encoder compresses ‚Üí decoder restores resolution, skip connections preserve details. Instance segmentation: distinguishes individual objects of same class (car_1, car_2). Mask R-CNN: bbox detection + binary mask for each object. Panoptic: combines semantic and instance. SAM (Segment Anything): universal model, works with any objects.',
      },
    },
  },
  {
    id: 'yolo',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: '‚ö°',
      level: 'implementation',
      ru: {
        label: 'YOLO',
        description: 'You Only Look Once ‚Äî –±—ã—Å—Ç—Ä—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –æ–±—ä–µ–∫—Ç–æ–≤ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏.',
        keyPoints: [
          'üöÄ –û–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥ = –¥–µ—Ç–µ–∫—Ü–∏—è –≤—Å–µ—Ö –æ–±—ä–µ–∫—Ç–æ–≤',
          '‚è±Ô∏è Real-time: 30-150+ FPS',
          'üìà –í–µ—Ä—Å–∏–∏: v1 (2016) ‚Üí v8 (2023) ‚Üí v11',
          'üéØ –ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏',
        ],
        howItWorks: 'YOLO –¥–µ–ª–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —Å–µ—Ç–∫—É SxS. –ö–∞–∂–¥–∞—è —è—á–µ–π–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç: B bounding boxes (x, y, w, h, confidence) + C –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∫–ª–∞—Å—Å–æ–≤. –í—Å—ë –∑–∞ –æ–¥–∏–Ω forward pass! Loss —Ñ—É–Ω–∫—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox + confidence + –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é. Anchor boxes: –ø—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã bbox (–≤—ã—Å–æ–∫–∏–µ, —à–∏—Ä–æ–∫–∏–µ, –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ). NMS —É–±–∏—Ä–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã. YOLOv8: —É–ª—É—á—à–µ–Ω–Ω—ã–π backbone (CSPDarknet), anchor-free –¥–µ—Ç–µ–∫—Ü–∏—è, decoupled head –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –æ—Ç–¥–µ–ª—å–Ω–æ.',
      },
      en: {
        label: 'YOLO',
        description: 'You Only Look Once ‚Äî fast real-time object detector.',
        keyPoints: [
          'üöÄ Single pass = detect all objects',
          '‚è±Ô∏è Real-time: 30-150+ FPS',
          'üìà Versions: v1 (2016) ‚Üí v8 (2023) ‚Üí v11',
          'üéØ Speed-accuracy tradeoff',
        ],
        howItWorks: 'YOLO divides image into SxS grid. Each cell predicts: B bounding boxes (x, y, w, h, confidence) + C class probabilities. All in single forward pass! Loss function combines: bbox coordinates + confidence + classification. Anchor boxes: predefined bbox shapes (tall, wide, square). NMS removes duplicates. YOLOv8: improved backbone (CSPDarknet), anchor-free detection, decoupled head for classification and regression separately.',
      },
    },
  },
  {
    id: 'resnet',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üèóÔ∏è',
      level: 'algorithm',
      ru: {
        label: 'ResNet',
        description: 'Residual Network ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å skip connections, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –æ–±—É—á–∞—Ç—å –æ—á–µ–Ω—å –≥–ª—É–±–æ–∫–∏–µ —Å–µ—Ç–∏.',
        keyPoints: [
          'üîó Skip connections: x + F(x)',
          'üìè –ì–ª—É–±–∏–Ω–∞: 18, 34, 50, 101, 152 —Å–ª–æ—è',
          'üèÜ –ü–æ–±–µ–¥–∏—Ç–µ–ª—å ImageNet 2015',
          'üß± –ë–∞–∑–æ–≤—ã–π backbone –¥–ª—è –º–Ω–æ–≥–∏—Ö –º–æ–¥–µ–ª–µ–π',
        ],
        howItWorks: '–ü—Ä–æ–±–ª–µ–º–∞: –æ—á–µ–Ω—å –≥–ª—É–±–æ–∫–∏–µ —Å–µ—Ç–∏ –ø–ª–æ—Ö–æ –æ–±—É—á–∞—é—Ç—Å—è (vanishing gradient, degradation). –†–µ—à–µ–Ω–∏–µ: residual –±–ª–æ–∫ —É—á–∏—Ç –Ω–µ F(x), –∞ F(x) + x (–æ—Å—Ç–∞—Ç–æ–∫). –ï—Å–ª–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –±–ª–∏–∑–∫–æ –∫ identity, –ª–µ–≥—á–µ –≤—ã—É—á–∏—Ç—å F(x) ‚âà 0. Skip connection –ø–æ–∑–≤–æ–ª—è–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—É —Ç–µ—á—å –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ –±–ª–æ–∫–∏. Bottleneck –±–ª–æ–∫: 1x1 conv (—É–º–µ–Ω—å—à–∏—Ç—å –∫–∞–Ω–∞–ª—ã) ‚Üí 3x3 conv ‚Üí 1x1 conv (—É–≤–µ–ª–∏—á–∏—Ç—å –æ–±—Ä–∞—Ç–Ω–æ). ResNet-50 = 50 —Å–ª–æ—ë–≤ —Å bottleneck –±–ª–æ–∫–∞–º–∏. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ backbone –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏, —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏, –∏ –¥—Ä.',
      },
      en: {
        label: 'ResNet',
        description: 'Residual Network ‚Äî architecture with skip connections enabling very deep networks.',
        keyPoints: [
          'üîó Skip connections: x + F(x)',
          'üìè Depth: 18, 34, 50, 101, 152 layers',
          'üèÜ ImageNet 2015 winner',
          'üß± Base backbone for many models',
        ],
        howItWorks: 'Problem: very deep networks train poorly (vanishing gradient, degradation). Solution: residual block learns not F(x), but F(x) + x (residual). If optimal transform is close to identity, easier to learn F(x) ‚âà 0. Skip connection allows gradient to flow directly through blocks. Bottleneck block: 1x1 conv (reduce channels) ‚Üí 3x3 conv ‚Üí 1x1 conv (increase back). ResNet-50 = 50 layers with bottleneck blocks. Used as backbone for detection, segmentation, etc.',
      },
    },
  },
  {
    id: 'gpt',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üí¨',
      level: 'implementation',
      ru: {
        label: 'GPT',
        description: 'Generative Pre-trained Transformer ‚Äî –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –æ—Ç OpenAI.',
        keyPoints: [
          'üìù Decoder-only —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä',
          'üéØ –û–±—É—á–µ–Ω–∏–µ: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞',
          'üìà GPT-1 (117M) ‚Üí GPT-4 (—Å–æ—Ç–Ω–∏ –º–ª—Ä–¥+ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—Ç–æ—á–Ω–æ–µ —á–∏—Å–ª–æ –Ω–µ —Ä–∞—Å–∫—Ä—ã—Ç–æ))',
          'üí° Emergent abilities: in-context learning, reasoning',
        ],
        howItWorks: '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: —Å—Ç–µ–∫ decoder –±–ª–æ–∫–æ–≤ —Å masked self-attention (–≤–∏–¥–∏—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª—ã–µ —Ç–æ–∫–µ–Ω—ã). Pre-training: –Ω–∞ —Ç—Ä–∏–ª–ª–∏–æ–Ω–∞—Ö —Ç–æ–∫–µ–Ω–æ–≤ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω. Fine-tuning: RLHF (–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è—Ö) –¥–ª—è —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º. Inference: –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É, –ø–æ–≤—Ç–æ—Ä—è–µ–º. Temperature –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç "–∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å". GPT-4: multimodal (—Ç–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è), —Å–æ—Ç–Ω–∏ –º–ª—Ä–¥+ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—Ç–æ—á–Ω–æ–µ —á–∏—Å–ª–æ –Ω–µ —Ä–∞—Å–∫—Ä—ã—Ç–æ), MoE –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞.',
      },
      en: {
        label: 'GPT',
        description: 'Generative Pre-trained Transformer ‚Äî autoregressive language model from OpenAI.',
        keyPoints: [
          'üìù Decoder-only transformer',
          'üéØ Training: next token prediction',
          'üìà GPT-1 (117M) ‚Üí GPT-4 (hundreds of billions+ (exact not disclosed))',
          'üí° Emergent abilities: in-context learning, reasoning',
        ],
        howItWorks: 'Architecture: stack of decoder blocks with masked self-attention (sees only past tokens). Pre-training: on trillions of text tokens predicts next token. Fine-tuning: RLHF (learning from human preferences) for instruction following. Inference: autoregressive generation ‚Äî predict token, add to context, repeat. Temperature controls "creativity". GPT-4: multimodal (text + images), hundreds of billions+ (exact not disclosed), MoE architecture.',
      },
    },
  },
  {
    id: 'bert',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üî§',
      level: 'implementation',
      ru: {
        label: 'BERT',
        description: 'Bidirectional Encoder Representations from Transformers ‚Äî –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞.',
        keyPoints: [
          'üìñ Encoder-only —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä',
          'üîÑ Bidirectional: –≤–∏–¥–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –æ–±–µ–∏—Ö —Å—Ç–æ—Ä–æ–Ω',
          'üé≠ Pre-training: MLM + NSP',
          'üèÜ SOTA –Ω–∞ –º–Ω–æ–≥–∏—Ö NLU –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö',
        ],
        howItWorks: '–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç GPT, BERT –∏—Å–ø–æ–ª—å–∑—É–µ—Ç encoder (bidirectional attention). Pre-training –∑–∞–¥–∞—á–∏: 1) MLM (Masked Language Model): –º–∞—Å–∫–∏—Ä—É–µ–º 15% —Ç–æ–∫–µ–Ω–æ–≤, –º–æ–¥–µ–ª—å –∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç. 2) NSP (Next Sentence Prediction): –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç, —Å–ª–µ–¥—É–µ—Ç –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ B –∑–∞ A. Fine-tuning: –¥–æ–±–∞–≤–ª—è–µ–º classification head –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ (sentiment, NER, QA). [CLS] —Ç–æ–∫–µ–Ω –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–∞. BERT-base: 12 —Å–ª–æ—ë–≤, 110M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. RoBERTa, ALBERT, DeBERTa ‚Äî —É–ª—É—á—à–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã.',
      },
      en: {
        label: 'BERT',
        description: 'Bidirectional Encoder Representations from Transformers ‚Äî text understanding model.',
        keyPoints: [
          'üìñ Encoder-only transformer',
          'üîÑ Bidirectional: sees context from both sides',
          'üé≠ Pre-training: MLM + NSP',
          'üèÜ SOTA on many NLU benchmarks',
        ],
        howItWorks: 'Unlike GPT, BERT uses encoder (bidirectional attention). Pre-training tasks: 1) MLM (Masked Language Model): mask 15% of tokens, model predicts them. 2) NSP (Next Sentence Prediction): predicts if sentence B follows A. Fine-tuning: add classification head for specific task (sentiment, NER, QA). [CLS] token aggregates information from entire text. BERT-base: 12 layers, 110M parameters. RoBERTa, ALBERT, DeBERTa ‚Äî improved variants.',
      },
    },
  },
  {
    id: 'clip',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üîó',
      level: 'implementation',
      ru: {
        label: 'CLIP',
        description: 'Contrastive Language-Image Pre-training ‚Äî —Å–≤—è–∑—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ç–µ–∫—Å—Ç –≤ –æ–±—â–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ.',
        keyPoints: [
          'üñºÔ∏è + üìù –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å',
          'üìä Contrastive learning –Ω–∞ 400M –ø–∞—Ä',
          'üéØ Zero-shot –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π',
          'üé® –û—Å–Ω–æ–≤–∞ –¥–ª—è Stable Diffusion, DALL-E',
        ],
        howItWorks: '–î–≤–∞ —ç–Ω–∫–æ–¥–µ—Ä–∞: Image Encoder (ViT –∏–ª–∏ ResNet) –∏ Text Encoder (Transformer). –û–±—É—á–µ–Ω–∏–µ: –Ω–∞ –ø–∞—Ä–∞—Ö (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ) –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞. Contrastive loss: –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç —Å—Ö–æ–¥—Å—Ç–≤–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø–∞—Ä, –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç –¥–ª—è –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö. –í batch –∏–∑ N –ø–∞—Ä —Å–æ–∑–¥–∞—ë—Ç—Å—è NxN –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞. –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è: –º–æ–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ª—é–±—ã–º —Ç–µ–∫—Å—Ç–æ–º! Zero-shot: "—Ñ–æ—Ç–æ –∫–æ—Ç–∞" vs "—Ñ–æ—Ç–æ —Å–æ–±–∞–∫–∏" ‚Äî –≤—ã–±–∏—Ä–∞–µ–º –∫–ª–∞—Å—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Å—Ö–æ–¥—Å—Ç–≤–æ–º. CLIP –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ text-to-image –º–æ–¥–µ–ª—è—Ö –¥–ª—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –ø—Ä–æ–º–ø—Ç—É.',
      },
      en: {
        label: 'CLIP',
        description: 'Contrastive Language-Image Pre-training ‚Äî connects images and text in shared space.',
        keyPoints: [
          'üñºÔ∏è + üìù Multimodal model',
          'üìä Contrastive learning on 400M pairs',
          'üéØ Zero-shot image classification',
          'üé® Foundation for Stable Diffusion, DALL-E',
        ],
        howItWorks: 'Two encoders: Image Encoder (ViT or ResNet) and Text Encoder (Transformer). Training: on (image, text description) pairs from internet. Contrastive loss: maximizes similarity of correct pairs, minimizes for incorrect. In batch of N pairs creates NxN similarity matrix. After training: can compare image with any text! Zero-shot: "photo of cat" vs "photo of dog" ‚Äî choose class with max similarity. CLIP used in text-to-image models to guide generation by text prompt.',
      },
    },
  },

  // ========== MORE IMPLEMENTATIONS ==========
  {
    id: 'vit',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üî≤',
      level: 'algorithm',
      ru: {
        label: 'Vision Transformer',
        description: 'ViT ‚Äî –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º —á–µ—Ä–µ–∑ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø–∞—Ç—á–∏.',
        keyPoints: [
          'üß© –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ‚Üí –ø–∞—Ç—á–∏ 16x16 ‚Üí —Ç–æ–∫–µ–Ω—ã',
          'üëÅÔ∏è Self-attention –º–µ–∂–¥—É –ø–∞—Ç—á–∞–º–∏',
          'üöÄ –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç CNN –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö',
          'üìä –¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è pre-training',
        ],
        howItWorks: '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 224x224 —Ä–∞–∑–±–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –ø–∞—Ç—á–∏ 16x16 = 196 –ø–∞—Ç—á–µ–π. –ö–∞–∂–¥—ã–π –ø–∞—Ç—á flatten\'–∏—Ç—Å—è –∏ –ø—Ä–æ–µ—Ü–∏—Ä—É–µ—Ç—Å—è –≤ embedding. –î–æ–±–∞–≤–ª—è–µ—Ç—Å—è positional encoding –∏ [CLS] —Ç–æ–∫–µ–Ω. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π Transformer encoder –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ç—á–µ–π. [CLS] —Ç–æ–∫–µ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ë–µ–∑ inductive bias CNN (–ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç—å, —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–æ–Ω–Ω–∞—è –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å), –ø–æ—ç—Ç–æ–º—É —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö. Pre-training –Ω–∞ ImageNet-21k (14M), –∑–∞—Ç–µ–º fine-tuning.',
      },
      en: {
        label: 'Vision Transformer',
        description: 'ViT ‚Äî applying transformer architecture to images by splitting into patches.',
        keyPoints: [
          'üß© Image ‚Üí 16x16 patches ‚Üí tokens',
          'üëÅÔ∏è Self-attention between patches',
          'üöÄ Outperforms CNN on large data',
          'üìä Requires lots of data for pre-training',
        ],
        howItWorks: 'Image 224x224 split into 16x16 patches = 196 patches. Each patch flattened and projected to embedding. Positional encoding and [CLS] token added. Standard Transformer encoder processes patch sequence. [CLS] token used for classification. Without CNN inductive bias (locality, translation invariance), so needs more data. Pre-training on ImageNet-21k (14M), then fine-tuning.',
      },
    },
  },
  {
    id: 'word2vec',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üìù',
      level: 'algorithm',
      ru: {
        label: 'Word2Vec',
        description: '–ê–ª–≥–æ—Ä–∏—Ç–º —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Å–ª–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.',
        keyPoints: [
          'üìä –°–ª–æ–≤–æ ‚Üí –≤–µ–∫—Ç–æ—Ä 100-300 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏',
          'üîÑ CBOW vs Skip-gram –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã',
          '‚ûï king - man + woman ‚âà queen',
          'üìÖ Google, 2013 ‚Äî –ø—Ä–æ—Ä—ã–≤ –≤ NLP',
        ],
        howItWorks: '–î–≤–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: CBOW (Continuous Bag of Words): –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–æ–≤–æ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É. Skip-gram: –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ —Å–ª–æ–≤—É. –û–±—É—á–µ–Ω–∏–µ: sliding window –ø–æ —Ç–µ–∫—Å—Ç—É, negative sampling –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏. –†–µ–∑—É–ª—å—Ç–∞—Ç: —Å–ª–æ–≤–∞ —Å –ø–æ—Ö–æ–∂–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–º–µ—é—Ç –±–ª–∏–∑–∫–∏–µ –≤–µ–∫—Ç–æ—Ä—ã. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞: vector("king") - vector("man") + vector("woman") ‚âà vector("queen"). –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä –Ω–∞ —Å–ª–æ–≤–æ, –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ–ª–∏—Å–µ–º–∏—é (bank = –±–∞–Ω–∫ –∏–ª–∏ –±–µ—Ä–µ–≥).',
      },
      en: {
        label: 'Word2Vec',
        description: 'Algorithm for creating word vector representations based on context.',
        keyPoints: [
          'üìä Word ‚Üí vector 100-300 dimensions',
          'üîÑ CBOW vs Skip-gram architectures',
          '‚ûï king - man + woman ‚âà queen',
          'üìÖ Google, 2013 ‚Äî NLP breakthrough',
        ],
        howItWorks: 'Two architectures: CBOW (Continuous Bag of Words): predicts word from context. Skip-gram: predicts context from word. Training: sliding window over text, negative sampling for efficiency. Result: words with similar context have close vectors. Semantic arithmetic: vector("king") - vector("man") + vector("woman") ‚âà vector("queen"). Limitation: one vector per word, doesn\'t handle polysemy (bank = financial or river).',
      },
    },
  },
  {
    id: 'rag',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üîç',
      level: 'method',
      ru: {
        label: 'RAG',
        description: 'Retrieval-Augmented Generation ‚Äî –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ LLM –≤–Ω–µ—à–Ω–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏ —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫.',
        keyPoints: [
          'üîé Retriever –Ω–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã',
          'üìù Generator –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏—Ö –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç',
          'üß† –†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–Ω–∞–Ω–∏–π LLM',
          'üíº –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: —á–∞—Ç-–±–æ—Ç—ã, QA —Å–∏—Å—Ç–µ–º—ã',
        ],
        howItWorks: '–ü–∞–π–ø–ª–∞–π–Ω: 1) –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ‚Üí embedding 2) –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ vector DB (FAISS, Pinecone) 3) Top-K –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤ prompt 4) LLM –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –º–µ–Ω—å—à–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π, –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. Chunking: –¥–æ–∫—É–º–µ–Ω—Ç—ã —Ä–∞–∑–±–∏–≤–∞—é—Ç—Å—è –Ω–∞ —á–∞—Å—Ç–∏ ~500 —Ç–æ–∫–µ–Ω–æ–≤. Reranking: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.',
      },
      en: {
        label: 'RAG',
        description: 'Retrieval-Augmented Generation ‚Äî augmenting LLM with external knowledge via search.',
        keyPoints: [
          'üîé Retriever finds relevant documents',
          'üìù Generator uses them as context',
          'üß† Solves LLM outdated knowledge problem',
          'üíº Applications: chatbots, QA systems',
        ],
        howItWorks: 'Pipeline: 1) User query ‚Üí embedding 2) Search similar docs in vector DB (FAISS, Pinecone) 3) Top-K docs added to prompt 4) LLM generates answer with context. Benefits: up-to-date info, fewer hallucinations, source citations. Chunking: documents split into ~500 token parts. Reranking: additional filtering of retrieved docs.',
      },
    },
  },
  {
    id: 'finetuning',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üéØ',
      level: 'method',
      ru: {
        label: 'Fine-tuning',
        description: '–ú–µ—Ç–æ–¥ –¥–æ–æ–±—É—á–µ–Ω–∏—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–π –∑–∞–¥–∞—á–µ.',
        keyPoints: [
          'üîÑ Pre-trained ‚Üí Fine-tuned –Ω–∞ —Å–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö',
          'üìâ –ú–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö —á–µ–º –æ–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è',
          'üéõÔ∏è –í–∞—Ä–∏–∞–Ω—Ç—ã: full, LoRA, prefix-tuning',
          '‚ö†Ô∏è –†–∏—Å–∫ catastrophic forgetting',
        ],
        howItWorks: 'Full fine-tuning: –æ–±–Ω–æ–≤–ª—è–µ–º –≤—Å–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –î–æ—Ä–æ–≥–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π. LoRA (Low-Rank Adaptation): –¥–æ–±–∞–≤–ª—è–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ trainable –º–∞—Ç—Ä–∏—Ü—ã –∫ –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º –≤–µ—Å–∞–º. A√óB –≥–¥–µ A –∏ B ‚Äî –Ω–∏–∑–∫–æ—Ä–∞–Ω–≥–æ–≤—ã–µ. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ: 0.1% –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. Prefix-tuning: –æ–±—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ "–≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã" –≤ –Ω–∞—á–∞–ª–µ. Prompt-tuning: –æ–±—É—á–∞–µ–º soft prompt. RLHF: fine-tuning —Å reward model –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π.',
      },
      en: {
        label: 'Fine-tuning',
        description: 'Method of adapting a pre-trained model to a specific task.',
        keyPoints: [
          'üîÑ Pre-trained ‚Üí Fine-tuned on your data',
          'üìâ Less data than training from scratch',
          'üéõÔ∏è Variants: full, LoRA, prefix-tuning',
          '‚ö†Ô∏è Risk of catastrophic forgetting',
        ],
        howItWorks: 'Full fine-tuning: update all model weights on new data. Expensive for large models. LoRA (Low-Rank Adaptation): add small trainable matrices to frozen weights. A√óB where A and B are low-rank. Efficient: 0.1% parameters. Prefix-tuning: train only "virtual tokens" at the start. Prompt-tuning: train soft prompt. RLHF: fine-tuning with reward model based on human preferences.',
      },
    },
  },
  {
    id: 'dropout',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üé≤',
      level: 'algorithm',
      ru: {
        label: 'Dropout',
        description: '–¢–µ—Ö–Ω–∏–∫–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ ‚Äî —Å–ª—É—á–∞–π–Ω–æ–µ "–≤—ã–∫–ª—é—á–µ–Ω–∏–µ" –Ω–µ–π—Ä–æ–Ω–æ–≤ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏.',
        keyPoints: [
          'üéØ –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ',
          'üìä –û–±—ã—á–Ω–æ p = 0.1-0.5',
          'üîÑ –ü—Ä–∏ inference –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –≤–µ—Å–∞',
          'üß† –≠—Ñ—Ñ–µ–∫—Ç: –∞–Ω—Å–∞–º–±–ª—å –ø–æ–¥—Å–µ—Ç–µ–π',
        ],
        howItWorks: '–ü—Ä–∏ –∫–∞–∂–¥–æ–º forward pass —Å–ª—É—á–∞–π–Ω–æ –æ–±–Ω—É–ª—è–µ–º p% –Ω–µ–π—Ä–æ–Ω–æ–≤. –†–∞–∑–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω—ã –ø—Ä–∏ –∫–∞–∂–¥–æ–º batch. –≠—Ç–æ –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç —Å–µ—Ç—å –Ω–µ –ø–æ–ª–∞–≥–∞—Ç—å—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω—ã ‚Äî —É—á–∏—Ç –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è. –ü—Ä–∏ inference –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –Ω–µ–π—Ä–æ–Ω—ã, –Ω–æ —É–º–Ω–æ–∂–∞–µ–º –Ω–∞ (1-p) –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∞. –ò–ª–∏ inverted dropout: –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –¥–µ–ª–∏–º –Ω–∞ (1-p), –ø—Ä–∏ inference –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º. –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: –æ–±—É—á–∞–µ–º —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –º–Ω–æ–≥–æ –ø–æ–¥—Å–µ—Ç–µ–π, inference ‚Äî —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ.',
      },
      en: {
        label: 'Dropout',
        description: 'Regularization technique ‚Äî randomly "turning off" neurons during training.',
        keyPoints: [
          'üéØ Prevents overfitting',
          'üìä Usually p = 0.1-0.5',
          'üîÑ Scale weights at inference',
          'üß† Effect: ensemble of subnetworks',
        ],
        howItWorks: 'Each forward pass randomly zeros p% of neurons. Different neurons each batch. Forces network not to rely on specific neurons ‚Äî learns redundant representations. At inference use all neurons but multiply by (1-p) for correct scale. Or inverted dropout: divide by (1-p) at training, nothing at inference. Interpretation: train exponentially many subnetworks, inference ‚Äî averaging.',
      },
    },
  },
  {
    id: 'batchnorm',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üìè',
      level: 'algorithm',
      ru: {
        label: 'Batch Normalization',
        description: '–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–π –ø–æ batch –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –∏ —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è.',
        keyPoints: [
          'üìä –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç mean=0, std=1 –ø–æ batch',
          'üéõÔ∏è Learnable Œ≥ –∏ Œ≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã',
          '‚ö° –ü–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã—à–µ learning rate',
          'üîÑ –ü—Ä–∏ inference –∏—Å–ø–æ–ª—å–∑—É–µ—Ç running stats',
        ],
        howItWorks: '–î–ª—è –∫–∞–∂–¥–æ–≥–æ batch: Œº = mean(x), œÉ¬≤ = var(x). –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: xÃÇ = (x - Œº) / ‚àö(œÉ¬≤ + Œµ). Scale –∏ shift: y = Œ≥xÃÇ + Œ≤ (learnable). –ó–∞—á–µ–º Œ≥ –∏ Œ≤? –ü–æ–∑–≤–æ–ª—è—é—Ç —Å–µ—Ç–∏ "–æ—Ç–º–µ–Ω–∏—Ç—å" –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ. –ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –∫–æ–ø–∏–º running mean/var. –ü—Ä–∏ inference –∏—Å–ø–æ–ª—å–∑—É–µ–º running stats (–Ω–µ batch stats). –ü—Ä–æ–±–ª–µ–º—ã: –∑–∞–≤–∏—Å–∏—Ç –æ—Ç batch size, –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è RNN. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã: LayerNorm (–ø–æ features), GroupNorm, InstanceNorm.',
      },
      en: {
        label: 'Batch Normalization',
        description: 'Normalizing activations across batch to stabilize and speed up training.',
        keyPoints: [
          'üìä Normalizes mean=0, std=1 across batch',
          'üéõÔ∏è Learnable Œ≥ and Œ≤ parameters',
          '‚ö° Allows higher learning rate',
          'üîÑ Uses running stats at inference',
        ],
        howItWorks: 'For each batch: Œº = mean(x), œÉ¬≤ = var(x). Normalization: xÃÇ = (x - Œº) / ‚àö(œÉ¬≤ + Œµ). Scale and shift: y = Œ≥xÃÇ + Œ≤ (learnable). Why Œ≥ and Œ≤? Allow network to "undo" normalization if needed. During training accumulate running mean/var. At inference use running stats (not batch stats). Issues: depends on batch size, doesn\'t work for RNN. Alternatives: LayerNorm (across features), GroupNorm, InstanceNorm.',
      },
    },
  },
  {
    id: 'adam',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üèÉ',
      level: 'algorithm',
      ru: {
        label: 'Adam Optimizer',
        description: 'Adaptive Moment Estimation ‚Äî –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º learning rate –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞.',
        keyPoints: [
          'üìä –ö–æ–º–±–∏–Ω–∞—Ü–∏—è Momentum + RMSprop',
          'üéØ –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π LR –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–µ—Å–∞',
          '‚ö° –ë—ã—Å—Ç—Ä–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å',
          'üîß Default: lr=0.001, Œ≤1=0.9, Œ≤2=0.999',
        ],
        howItWorks: '–•—Ä–∞–Ω–∏—Ç –¥–≤–∞ –º–æ–º–µ–Ω—Ç–∞: m (—Å—Ä–µ–¥–Ω–µ–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤, –∫–∞–∫ momentum) –∏ v (—Å—Ä–µ–¥–Ω–µ–µ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤, –∫–∞–∫ RMSprop). m_t = Œ≤1¬∑m_{t-1} + (1-Œ≤1)¬∑g_t, v_t = Œ≤2¬∑v_{t-1} + (1-Œ≤2)¬∑g_t¬≤. Bias correction: mÃÇ = m/(1-Œ≤1^t), vÃÇ = v/(1-Œ≤2^t). Update: Œ∏ = Œ∏ - lr¬∑mÃÇ/(‚àövÃÇ + Œµ). –ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å –º–∞–ª–µ–Ω—å–∫–∏–º–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏ –ø–æ–ª—É—á–∞—é—Ç –±–æ–ª—å—à–∏–µ —à–∞–≥–∏ –∏ –Ω–∞–æ–±–æ—Ä–æ—Ç. AdamW: –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π weight decay (L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç Adam).',
      },
      en: {
        label: 'Adam Optimizer',
        description: 'Adaptive Moment Estimation ‚Äî optimizer with adaptive learning rate per parameter.',
        keyPoints: [
          'üìä Combines Momentum + RMSprop',
          'üéØ Adaptive LR for each weight',
          '‚ö° Fast convergence',
          'üîß Default: lr=0.001, Œ≤1=0.9, Œ≤2=0.999',
        ],
        howItWorks: 'Stores two moments: m (gradient average, like momentum) and v (squared gradient average, like RMSprop). m_t = Œ≤1¬∑m_{t-1} + (1-Œ≤1)¬∑g_t, v_t = Œ≤2¬∑v_{t-1} + (1-Œ≤2)¬∑g_t¬≤. Bias correction: mÃÇ = m/(1-Œ≤1^t), vÃÇ = v/(1-Œ≤2^t). Update: Œ∏ = Œ∏ - lr¬∑mÃÇ/(‚àövÃÇ + Œµ). Adaptivity: parameters with small gradients get larger steps and vice versa. AdamW: corrected weight decay (L2 regularization separate from Adam).',
      },
    },
  },
  {
    id: 'agents',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'ü§ñ',
      level: 'implementation',
      ru: {
        label: 'AI Agents',
        description: '–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –Ω–∞ –±–∞–∑–µ LLM, —Å–ø–æ—Å–æ–±–Ω—ã–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∏ –≤—ã–ø–æ–ª–Ω—è—Ç—å –¥–µ–π—Å—Ç–≤–∏—è.',
        keyPoints: [
          'üß† LLM –∫–∞–∫ "–º–æ–∑–≥" –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π',
          'üîß Tools: –ø–æ–∏—Å–∫, –∫–æ–¥, API, –±—Ä–∞—É–∑–µ—Ä',
          'üìã Planning: —Ä–∞–∑–±–∏–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –Ω–∞ —à–∞–≥–∏',
          'üîÑ ReAct: Reasoning + Acting —Ü–∏–∫–ª',
        ],
        howItWorks: '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∞–≥–µ–Ω—Ç–∞: 1) Perception ‚Äî –ø–æ–ª—É—á–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö 2) Planning ‚Äî LLM —Ä–∞–∑–±–∏–≤–∞–µ—Ç –∑–∞–¥–∞—á—É –Ω–∞ –ø–æ–¥–∑–∞–¥–∞—á–∏ 3) Action ‚Äî –≤—ã–±–æ—Ä –∏ –≤—ã–∑–æ–≤ tool 4) Observation ‚Äî –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ 5) Repeat. ReAct –ø–∞—Ç—Ç–µ—Ä–Ω: Thought ‚Üí Action ‚Üí Observation ‚Üí Thought... Memory: short-term (–∫–æ–Ω—Ç–µ–∫—Å—Ç) –∏ long-term (vector DB). –ü—Ä–∏–º–µ—Ä—ã: AutoGPT, LangChain agents, OpenAI Assistants. –ü—Ä–æ–±–ª–µ–º—ã: –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏, –∑–∞—Å—Ç—Ä–µ–≤–∞–Ω–∏–µ –≤ —Ü–∏–∫–ª–∞—Ö, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å.',
      },
      en: {
        label: 'AI Agents',
        description: 'Autonomous LLM-based systems capable of planning and executing actions.',
        keyPoints: [
          'üß† LLM as "brain" for reasoning',
          'üîß Tools: search, code, API, browser',
          'üìã Planning: breaking task into steps',
          'üîÑ ReAct: Reasoning + Acting cycle',
        ],
        howItWorks: 'Agent architecture: 1) Perception ‚Äî receive input 2) Planning ‚Äî LLM breaks task into subtasks 3) Action ‚Äî select and call tool 4) Observation ‚Äî analyze result 5) Repeat. ReAct pattern: Thought ‚Üí Action ‚Üí Observation ‚Üí Thought... Memory: short-term (context) and long-term (vector DB). Examples: AutoGPT, LangChain agents, OpenAI Assistants. Issues: hallucinations, getting stuck in loops, safety.',
      },
    },
  },

  // ========== MORE ML ALGORITHMS ==========
  {
    id: 'logreg',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üìà',
      level: 'algorithm',
      ru: {
        label: 'Logistic Regression',
        description: '–ê–ª–≥–æ—Ä–∏—Ç–º –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ —Å–∏–≥–º–æ–∏–¥—É.',
        keyPoints: [
          'üéØ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞: 0-1',
          'üìä Sigmoid: œÉ(z) = 1/(1+e^(-z))',
          'üìâ Loss: Binary Cross-Entropy',
          '‚ö° –ë—ã—Å—Ç—Ä—ã–π, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–π',
        ],
        howItWorks: '–õ–∏–Ω–µ–π–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ z = wx + b –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ —Å–∏–≥–º–æ–∏–¥—É: P(y=1|x) = œÉ(z). –°–∏–≥–º–æ–∏–¥–∞ —Å–∂–∏–º–∞–µ—Ç –ª—é–±–æ–µ —á–∏—Å–ª–æ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω (0,1) ‚Äî –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º –∫–∞–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å. –ü–æ—Ä–æ–≥ –æ–±—ã—á–Ω–æ 0.5: –µ—Å–ª–∏ P > 0.5 ‚Üí –∫–ª–∞—Å—Å 1. –û–±—É—á–µ–Ω–∏–µ: –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è BCE loss = -[y¬∑log(p) + (1-y)¬∑log(1-p)]. –î–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π: Softmax Regression (softmax –≤–º–µ—Å—Ç–æ sigmoid).',
      },
      en: {
        label: 'Logistic Regression',
        description: 'Binary classification algorithm using sigmoid function.',
        keyPoints: [
          'üéØ Class probability: 0-1',
          'üìä Sigmoid: œÉ(z) = 1/(1+e^(-z))',
          'üìâ Loss: Binary Cross-Entropy',
          '‚ö° Fast, interpretable',
        ],
        howItWorks: 'Linear combination z = wx + b passed through sigmoid: P(y=1|x) = œÉ(z). Sigmoid squashes any number to (0,1) range ‚Äî interpret as probability. Threshold usually 0.5: if P > 0.5 ‚Üí class 1. Training: minimize BCE loss = -[y¬∑log(p) + (1-y)¬∑log(1-p)]. For multiclass: Softmax Regression (softmax instead of sigmoid).',
      },
    },
  },
  {
    id: 'xgboost',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üöÄ',
      level: 'algorithm',
      ru: {
        label: 'XGBoost',
        description: 'Extreme Gradient Boosting ‚Äî –º–æ—â–Ω—ã–π –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–∞ –¥–µ—Ä–µ–≤—å—è—Ö.',
        keyPoints: [
          'üå≥ Gradient Boosting –Ω–∞ –¥–µ—Ä–µ–≤—å—è—Ö',
          'üèÜ –¢–æ–ø –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö',
          '‚ö° –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è + –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è',
          'üìä Kaggle killer',
        ],
        howItWorks: 'Gradient Boosting: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Å—Ç—Ä–æ–∏–º –¥–µ—Ä–µ–≤—å—è, –∫–∞–∂–¥–æ–µ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö. XGBoost –¥–æ–±–∞–≤–ª—è–µ—Ç: 1) L1/L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ 2) –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ split 3) –û–±—Ä–∞–±–æ—Ç–∫—É –ø—Ä–æ–ø—É—Å–∫–æ–≤ 4) –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ—Ä–µ–≤—å–µ–≤. Loss –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞ –ø–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—É. –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: n_estimators, max_depth, learning_rate, subsample. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã: LightGBM (–±—ã—Å—Ç—Ä–µ–µ), CatBoost (–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Ñ–∏—á–∏).',
      },
      en: {
        label: 'XGBoost',
        description: 'Extreme Gradient Boosting ‚Äî powerful tree-based ensemble algorithm.',
        keyPoints: [
          'üå≥ Gradient Boosting on trees',
          'üèÜ Top algorithm for tabular data',
          '‚ö° Regularization + parallelization',
          'üìä Kaggle killer',
        ],
        howItWorks: 'Gradient Boosting: sequentially build trees, each corrects errors of previous. XGBoost adds: 1) L1/L2 regularization for complexity control 2) Optimized split finding algorithm 3) Missing value handling 4) Parallel tree building. Loss optimized via gradient descent on functional. Hyperparameters: n_estimators, max_depth, learning_rate, subsample. Alternatives: LightGBM (faster), CatBoost (categorical features).',
      },
    },
  },
  {
    id: 'autoencoder',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üîÑ',
      level: 'algorithm',
      ru: {
        label: 'Autoencoder',
        description: '–ù–µ–π—Ä–æ—Å–µ—Ç—å, –æ–±—É—á–∞—é—â–∞—è—Å—è —Å–∂–∏–º–∞—Ç—å –∏ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ.',
        keyPoints: [
          'üì¶ Encoder: –¥–∞–Ω–Ω—ã–µ ‚Üí latent space',
          'üì§ Decoder: latent ‚Üí —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è',
          'üéØ Loss: reconstruction error',
          'üîç –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: —Å–∂–∞—Ç–∏–µ, denoising, anomaly detection',
        ],
        howItWorks: '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–µ—Å–æ—á–Ω—ã—Ö —á–∞—Å–æ–≤: input ‚Üí encoder (—Å–∂–∞—Ç–∏–µ) ‚Üí bottleneck (latent) ‚Üí decoder (–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ) ‚Üí output. –¶–µ–ª—å: output ‚âà input. Bottleneck –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç —Å–µ—Ç—å —É—á–∏—Ç—å –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏. Denoising AE: –¥–æ–±–∞–≤–ª—è–µ–º —à—É–º –∫–æ –≤—Ö–æ–¥—É, —É—á–∏–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å —á–∏—Å—Ç—ã–π. Sparse AE: —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏. Contractive AE: —à—Ç—Ä–∞—Ñ –Ω–∞ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –≤—Ö–æ–¥—É. Variational AE (VAE): latent –∫–∞–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ.',
      },
      en: {
        label: 'Autoencoder',
        description: 'Neural network learning to compress and reconstruct data.',
        keyPoints: [
          'üì¶ Encoder: data ‚Üí latent space',
          'üì§ Decoder: latent ‚Üí reconstruction',
          'üéØ Loss: reconstruction error',
          'üîç Uses: compression, denoising, anomaly detection',
        ],
        howItWorks: 'Hourglass architecture: input ‚Üí encoder (compress) ‚Üí bottleneck (latent) ‚Üí decoder (reconstruct) ‚Üí output. Goal: output ‚âà input. Bottleneck forces network to learn important features. Denoising AE: add noise to input, learn to reconstruct clean. Sparse AE: regularization on activations. Contractive AE: penalty on input sensitivity. Variational AE (VAE): latent as distribution.',
      },
    },
  },
  {
    id: 'unet',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üè•',
      level: 'implementation',
      ru: {
        label: 'U-Net',
        description: '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å encoder-decoder –∏ skip connections.',
        keyPoints: [
          'üèóÔ∏è U-–æ–±—Ä–∞–∑–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞',
          'üîó Skip connections —Å–æ—Ö—Ä–∞–Ω—è—é—Ç –¥–µ—Ç–∞–ª–∏',
          'üè• –ò–∑–Ω–∞—á–∞–ª—å–Ω–æ –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π',
          '‚úÇÔ∏è Pixel-level predictions',
        ],
        howItWorks: 'Encoder (–ª–µ–≤–∞—è —á–∞—Å—Ç—å U): —Å–≤—ë—Ä—Ç–∫–∏ + pooling, —Å–∂–∏–º–∞–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–∞–Ω–∞–ª—ã. Decoder (–ø—Ä–∞–≤–∞—è —á–∞—Å—Ç—å): upsampling + —Å–≤—ë—Ä—Ç–∫–∏, –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ. Skip connections: –∫–æ–ø–∏—Ä—É–µ–º feature maps —Å encoder –Ω–∞ decoder —Ç–æ–≥–æ –∂–µ —É—Ä–æ–≤–Ω—è. –≠—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ–ª–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Ä—è—é—Ç—Å—è –ø—Ä–∏ —Å–∂–∞—Ç–∏–∏. –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–π: 1x1 conv –¥–ª—è –∫–∞—Ä—Ç—ã –∫–ª–∞—Å—Å–æ–≤. –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏: U-Net++, Attention U-Net, ResUNet.',
      },
      en: {
        label: 'U-Net',
        description: 'Segmentation architecture with encoder-decoder and skip connections.',
        keyPoints: [
          'üèóÔ∏è U-shaped structure',
          'üîó Skip connections preserve details',
          'üè• Originally for medical images',
          '‚úÇÔ∏è Pixel-level predictions',
        ],
        howItWorks: 'Encoder (left part of U): convolutions + pooling, compress spatially, increase channels. Decoder (right part): upsampling + convolutions, restore resolution. Skip connections: copy feature maps from encoder to decoder at same level. This preserves fine details lost during compression. Final layer: 1x1 conv for class map. Variants: U-Net++, Attention U-Net, ResUNet.',
      },
    },
  },
  {
    id: 'stable-diffusion',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üé®',
      level: 'implementation',
      ru: {
        label: 'Stable Diffusion',
        description: '–û—Ç–∫—Ä—ã—Ç–∞—è –º–æ–¥–µ–ª—å text-to-image –Ω–∞ –æ—Å–Ω–æ–≤–µ latent diffusion.',
        keyPoints: [
          'üñºÔ∏è Text ‚Üí Image –≥–µ–Ω–µ—Ä–∞—Ü–∏—è',
          'üì¶ –†–∞–±–æ—Ç–∞–µ—Ç –≤ latent space (–±—ã—Å—Ç—Ä–µ–µ)',
          'üîì Open source, –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ',
          'üéõÔ∏è ControlNet, LoRA –¥–ª—è –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏–∏',
        ],
        howItWorks: 'Latent Diffusion: –≤–º–µ—Å—Ç–æ —Ä–∞–±–æ—Ç—ã —Å –ø–∏–∫—Å–µ–ª—è–º–∏ —Ä–∞–±–æ—Ç–∞–µ–º —Å latent vectors (VAE encoder —Å–∂–∏–º–∞–µ—Ç, decoder –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç). –¢–µ–∫—Å—Ç–æ–≤—ã–π prompt ‚Üí CLIP text encoder ‚Üí conditioning. U-Net –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —à—É–º –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ. Classifier-free guidance: —É—Å–∏–ª–∏–≤–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–º–ø—Ç—É. Sampling: –Ω–∞—á–∏–Ω–∞–µ–º —Å —à—É–º–∞, –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ —É–±–∏—Ä–∞–µ–º. SDXL: —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –¥–≤—É–º—è text encoders. ControlNet: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å —á–µ—Ä–µ–∑ –ø–æ–∑—ã, edges, depth maps.',
      },
      en: {
        label: 'Stable Diffusion',
        description: 'Open-source text-to-image model based on latent diffusion.',
        keyPoints: [
          'üñºÔ∏è Text ‚Üí Image generation',
          'üì¶ Works in latent space (faster)',
          'üîì Open source, can run locally',
          'üéõÔ∏è ControlNet, LoRA for customization',
        ],
        howItWorks: 'Latent Diffusion: instead of working with pixels, work with latent vectors (VAE encoder compresses, decoder reconstructs). Text prompt ‚Üí CLIP text encoder ‚Üí conditioning. U-Net predicts noise at each step. Classifier-free guidance: strengthens prompt adherence. Sampling: start from noise, iteratively remove. SDXL: improved version with two text encoders. ControlNet: additional control via poses, edges, depth maps.',
      },
    },
  },
  {
    id: 'prompt-eng',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: '‚úçÔ∏è',
      level: 'method',
      ru: {
        label: 'Prompt Engineering',
        description: '–ò—Å–∫—É—Å—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è LLM.',
        keyPoints: [
          'üìù –°—Ç—Ä—É–∫—Ç—É—Ä–∞: —Ä–æ–ª—å, –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∑–∞–¥–∞—á–∞, —Ñ–æ—Ä–º–∞—Ç',
          'üéØ Few-shot: –ø—Ä–∏–º–µ—Ä—ã –≤ –ø—Ä–æ–º–ø—Ç–µ',
          'üîÑ –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ',
          '‚ö†Ô∏è –í–∞–∂–Ω–æ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ output',
        ],
        howItWorks: '–¢–µ—Ö–Ω–∏–∫–∏: 1) Zero-shot: –ø—Ä–æ—Å—Ç–æ –æ–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–¥–∞—á—É 2) Few-shot: –¥–∞—ë–º –ø—Ä–∏–º–µ—Ä—ã input‚Üíoutput 3) Chain of Thought: –ø—Ä–æ—Å–∏–º –¥—É–º–∞—Ç—å —à–∞–≥ –∑–∞ —à–∞–≥–æ–º 4) Role prompting: "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –≤..." 5) Format specification: "–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON". System prompt –∑–∞–¥–∞—ë—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ. Temperature –≤–ª–∏—è–µ—Ç –Ω–∞ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å. Negative prompting: —á—Ç–æ –ù–ï –¥–µ–ª–∞—Ç—å. –î–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏: —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π output (JSON, XML).',
      },
      en: {
        label: 'Prompt Engineering',
        description: 'Art of crafting effective prompts for LLMs.',
        keyPoints: [
          'üìù Structure: role, context, task, format',
          'üéØ Few-shot: examples in prompt',
          'üîÑ Iterative improvement',
          '‚ö†Ô∏è Critical for output quality',
        ],
        howItWorks: 'Techniques: 1) Zero-shot: just describe task 2) Few-shot: give input‚Üíoutput examples 3) Chain of Thought: ask to think step by step 4) Role prompting: "You are an expert in..." 5) Format specification: "Reply in JSON format". System prompt sets behavior. Temperature affects creativity. Negative prompting: what NOT to do. For stability: structured output (JSON, XML).',
      },
    },
  },
  {
    id: 'cot',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üîó',
      level: 'method',
      ru: {
        label: 'Chain of Thought',
        description: '–¢–µ—Ö–Ω–∏–∫–∞ –ø—Ä–æ–º–ø—Ç–∏–Ω–≥–∞ –¥–ª—è –ø–æ—à–∞–≥–æ–≤–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è LLM.',
        keyPoints: [
          'üß† "–î—É–º–∞–π —à–∞–≥ –∑–∞ —à–∞–≥–æ–º"',
          'üìà –£–ª—É—á—à–∞–µ—Ç reasoning –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö',
          'üî¢ –û—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∏ –ª–æ–≥–∏–∫–∏',
          'üí° Zero-shot CoT: –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤—å —Ñ—Ä–∞–∑—É',
        ],
        howItWorks: '–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç: "–†–µ—à–∏ –∑–∞–¥–∞—á—É: ..." ‚Üí –º–æ–¥–µ–ª—å —Å—Ä–∞–∑—É –¥–∞—ë—Ç –æ—Ç–≤–µ—Ç (—á–∞—Å—Ç–æ –Ω–µ–≤–µ—Ä–Ω—ã–π –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á). CoT –ø—Ä–æ–º–ø—Ç: "–†–µ—à–∏ –∑–∞–¥–∞—á—É, –¥—É–º–∞—è —à–∞–≥ –∑–∞ —à–∞–≥–æ–º: ..." ‚Üí –º–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è ‚Üí —Ç–æ—á–Ω–µ–µ –Ω–∞ –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã—Ö –∑–∞–¥–∞—á–∞—Ö. Few-shot CoT: –¥–∞—ë–º –ø—Ä–∏–º–µ—Ä—ã —Å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º–∏. Self-consistency: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ CoT, –≤—ã–±–∏—Ä–∞–µ–º majority answer. Tree of Thought: –∏—Å—Å–ª–µ–¥—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø—É—Ç–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π. –†–∞–±–æ—Ç–∞–µ—Ç –±–ª–∞–≥–æ–¥–∞—Ä—è —Ç–æ–º—É —á—Ç–æ –º–æ–¥–µ–ª—å "–≤–∏–¥–∏—Ç" –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —à–∞–≥–∏.',
      },
      en: {
        label: 'Chain of Thought',
        description: 'Prompting technique for step-by-step LLM reasoning.',
        keyPoints: [
          'üß† "Think step by step"',
          'üìà Improves reasoning on complex tasks',
          'üî¢ Especially for math and logic',
          'üí° Zero-shot CoT: just add the phrase',
        ],
        howItWorks: 'Standard prompt: "Solve: ..." ‚Üí model gives answer directly (often wrong for complex tasks). CoT prompt: "Solve, thinking step by step: ..." ‚Üí model shows reasoning ‚Üí more accurate on multi-step tasks. Few-shot CoT: give examples with reasoning. Self-consistency: generate multiple CoTs, pick majority answer. Tree of Thought: explore different reasoning paths. Works because model "sees" intermediate steps.',
      },
    },
  },
  {
    id: 'moe',
    position: { x: 0, y: 0 },
    type: 'custom',
    data: {
      emoji: 'üéõÔ∏è',
      level: 'algorithm',
      ru: {
        label: 'Mixture of Experts',
        description: '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–¥—Å–µ—Ç–µ–π –∏ —Ä–æ—É—Ç–µ—Ä–æ–º.',
        keyPoints: [
          'üß† N —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –∞–∫—Ç–∏–≤–∏—Ä—É—é—Ç—Å—è K',
          'üö¶ Router –≤—ã–±–∏—Ä–∞–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–æ–≤',
          '‚ö° Sparse: –º–µ–Ω—å—à–µ compute –ø—Ä–∏ inference',
          'üìà GPT-4, Mixtral –∏—Å–ø–æ–ª—å–∑—É—é—Ç MoE',
        ],
        howItWorks: '–í–º–µ—Å—Ç–æ –æ–¥–Ω–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ FFN ‚Äî N –º–∞–ª–µ–Ω—å–∫–∏—Ö "—ç–∫—Å–ø–µ—Ä—Ç–æ–≤". Router (–æ–±—É—á–∞–µ–º—ã–π) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –≤—ã–±–∏—Ä–∞–µ—Ç top-K —ç–∫—Å–ø–µ—Ä—Ç–æ–≤. –¢–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–µ—Ä—Ç—ã –∞–∫—Ç–∏–≤–∏—Ä—É—é—Ç—Å—è ‚Üí sparse computation. –ù–∞–ø—Ä–∏–º–µ—Ä: 8 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –∞–∫—Ç–∏–≤–∏—Ä—É–µ–º 2 ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º 25% –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. Load balancing loss: —á—Ç–æ–±—ã —ç–∫—Å–ø–µ—Ä—Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ. –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: –º–æ–∂–µ–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±–µ–∑ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–æ—Å—Ç–∞ compute. Mixtral 8x7B: 8 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ 7B, –∞–∫—Ç–∏–≤–Ω–æ 2, –∫–∞—á–µ—Å—Ç–≤–æ –∫–∞–∫ —É 70B –º–æ–¥–µ–ª–∏.',
      },
      en: {
        label: 'Mixture of Experts',
        description: 'Architecture with multiple specialized subnetworks and a router.',
        keyPoints: [
          'üß† N experts, K activated',
          'üö¶ Router selects experts',
          '‚ö° Sparse: less compute at inference',
          'üìà GPT-4, Mixtral use MoE',
        ],
        howItWorks: 'Instead of one large FFN ‚Äî N small "experts". Router (learnable) for each token selects top-K experts. Only selected experts activate ‚Üí sparse computation. Example: 8 experts, activate 2 ‚Üí use 25% parameters. Load balancing loss: so experts are used evenly. Benefits: can scale parameters without proportional compute growth. Mixtral 8x7B: 8 experts of 7B each, 2 active, quality like 70B model.',
      },
    },
  },
];

// ==================== EDGES ====================

export const initialEdges: Edge[] = [
  // AI ‚Üí Theories
  { id: 'ai-ml', source: 'ai', target: 'ml', animated: true },
  { id: 'ai-dl', source: 'ai', target: 'dl', animated: true },
  { id: 'ai-nlp', source: 'ai', target: 'nlp', animated: true },
  
  // ML ‚Üí Methods
  { id: 'ml-sup', source: 'ml', target: 'supervised' },
  { id: 'ml-unsup', source: 'ml', target: 'unsupervised' },
  { id: 'ml-rl', source: 'ml', target: 'rl' },
  
  // Supervised ‚Üí Algorithms
  { id: 'sup-linreg', source: 'supervised', target: 'linear-reg' },
  { id: 'sup-tree', source: 'supervised', target: 'decision-tree' },
  { id: 'sup-rf', source: 'supervised', target: 'random-forest' },
  { id: 'sup-svm', source: 'supervised', target: 'svm' },
  
  // Unsupervised ‚Üí Algorithms
  { id: 'unsup-kmeans', source: 'unsupervised', target: 'kmeans' },
  { id: 'unsup-pca', source: 'unsupervised', target: 'pca' },
  
  // RL ‚Üí Algorithms
  { id: 'rl-qlearn', source: 'rl', target: 'qlearning' },
  
  // DL ‚Üí Architectures
  { id: 'dl-nn', source: 'dl', target: 'nn' },
  { id: 'dl-cnn', source: 'dl', target: 'cnn' },
  { id: 'dl-rnn', source: 'dl', target: 'rnn' },
  { id: 'rnn-lstm', source: 'rnn', target: 'lstm' },
  { id: 'dl-trans', source: 'dl', target: 'transformer' },
  { id: 'trans-attn', source: 'transformer', target: 'attention' },
  { id: 'dl-gan', source: 'dl', target: 'gan' },
  { id: 'dl-vae', source: 'dl', target: 'vae' },
  { id: 'dl-diff', source: 'dl', target: 'diffusion' },
  
  // NLP ‚Üí Implementations
  { id: 'nlp-llm', source: 'nlp', target: 'llm' },
  { id: 'nlp-emb', source: 'nlp', target: 'embeddings' },
  { id: 'nlp-tok', source: 'nlp', target: 'tokenization' },
  
  // Computer Vision branch
  { id: 'ai-cv', source: 'ai', target: 'cv', animated: true },
  { id: 'cv-detection', source: 'cv', target: 'obj-detection' },
  { id: 'cv-classification', source: 'cv', target: 'img-classification' },
  { id: 'cv-segmentation', source: 'cv', target: 'segmentation' },
  { id: 'detection-yolo', source: 'obj-detection', target: 'yolo' },
  { id: 'classification-resnet', source: 'img-classification', target: 'resnet' },
  
  // LLM implementations
  { id: 'llm-gpt', source: 'llm', target: 'gpt' },
  { id: 'trans-bert', source: 'transformer', target: 'bert' },
  
  // CLIP - connects CV and NLP
  { id: 'cv-clip', source: 'cv', target: 'clip', style: { strokeDasharray: '5,5' } },
  { id: 'nlp-clip', source: 'nlp', target: 'clip', style: { strokeDasharray: '5,5' } },
  
  // New nodes
  { id: 'cv-vit', source: 'cv', target: 'vit' },
  { id: 'emb-word2vec', source: 'embeddings', target: 'word2vec' },
  { id: 'llm-rag', source: 'llm', target: 'rag' },
  { id: 'llm-finetuning', source: 'llm', target: 'finetuning' },
  { id: 'nn-dropout', source: 'nn', target: 'dropout' },
  { id: 'nn-batchnorm', source: 'nn', target: 'batchnorm' },
  { id: 'nn-adam', source: 'nn', target: 'adam' },
  { id: 'llm-agents', source: 'llm', target: 'agents' },
  
  // New ML algorithms
  { id: 'sup-logreg', source: 'supervised', target: 'logreg' },
  { id: 'sup-xgboost', source: 'supervised', target: 'xgboost' },
  
  // New DL
  { id: 'dl-autoencoder', source: 'dl', target: 'autoencoder' },
  { id: 'seg-unet', source: 'segmentation', target: 'unet' },
  { id: 'diff-sd', source: 'diffusion', target: 'stable-diffusion' },
  { id: 'dl-moe', source: 'dl', target: 'moe' },
  
  // NLP/LLM techniques
  { id: 'llm-prompt', source: 'llm', target: 'prompt-eng' },
  { id: 'prompt-cot', source: 'prompt-eng', target: 'cot' },
  
  // Cross-connections (dashed = —Å–≤—è–∑—å –º–µ–∂–¥—É –≤–µ—Ç–∫–∞–º–∏)
  { id: 'trans-llm', source: 'transformer', target: 'llm', style: { strokeDasharray: '5,5' } },
  { id: 'sup-nn', source: 'supervised', target: 'nn', style: { strokeDasharray: '5,5' } },
  { id: 'tree-rf', source: 'decision-tree', target: 'random-forest', style: { strokeDasharray: '5,5' } },
  { id: 'attn-llm', source: 'attention', target: 'llm', style: { strokeDasharray: '5,5' } },
  { id: 'cnn-cv', source: 'cnn', target: 'cv', style: { strokeDasharray: '5,5' } },
  { id: 'cnn-resnet', source: 'cnn', target: 'resnet', style: { strokeDasharray: '5,5' } },
  { id: 'trans-vit', source: 'transformer', target: 'vit', style: { strokeDasharray: '5,5' } },
  { id: 'rag-agents', source: 'rag', target: 'agents', style: { strokeDasharray: '5,5' } },
  { id: 'moe-gpt', source: 'moe', target: 'gpt', style: { strokeDasharray: '5,5' } },
  { id: 'vae-autoenc', source: 'vae', target: 'autoencoder', style: { strokeDasharray: '5,5' } },
];
